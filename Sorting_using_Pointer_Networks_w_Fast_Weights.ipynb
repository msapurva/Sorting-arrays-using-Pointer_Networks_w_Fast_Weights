{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sorting_using_Pointer_Networks_w_Fast_Weights.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msapurva/Sorting-arrays-using-Pointer_Networks_w_Fast_Weights/blob/master/Sorting_using_Pointer_Networks_w_Fast_Weights.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zWFaAnmetOTr",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime as dt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-zyK1oRMrp0l",
        "colab": {}
      },
      "source": [
        "tf.enable_eager_execution()\n",
        "np.random.seed(42)\n",
        "tf.random.set_random_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KH5gPEjcrp0n"
      },
      "source": [
        "### Experiment Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sWdDXmrXrp0n",
        "outputId": "c41e68a2-7555-4e82-ec39-1fc003156094",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "hidden_dimensions=128 # epoch configuration defined later below\n",
        "\n",
        "minSeqSize=3\n",
        "maxSeqSize=5\n",
        "\n",
        "batchSize=32\n",
        "numOfBatches=150\n",
        "datasize=batchSize*numOfBatches*(maxSeqSize-minSeqSize+1)\n",
        "\n",
        "datasize\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wmYMjSIyL2F8"
      },
      "source": [
        "### Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xbja4GErPikD",
        "colab": {}
      },
      "source": [
        "def makeData(minSeqSize,maxSeqSize,batchSize,numOfBatches):\n",
        "    X={}\n",
        "    Y={}\n",
        "    datasize=batchSize*numOfBatches*(maxSeqSize-minSeqSize+1)\n",
        "\n",
        "    for seqLen in range(minSeqSize,maxSeqSize+1):\n",
        "        X[seqLen]=[]\n",
        "        Y[seqLen]=[]\n",
        "\n",
        "        for dataidx in range(int(datasize/(maxSeqSize-minSeqSize+1))):\n",
        "            seqBase=np.random.uniform(size=(seqLen))\n",
        "            aSeq=seqBase\n",
        "            X[seqLen]+=[aSeq]\n",
        "            \n",
        "            # Y\n",
        "            aRec=[]\n",
        "            for e in np.sort(seqBase):\n",
        "                idx=list(seqBase).index(e)\n",
        "                aRec+=[np.zeros(seqLen,dtype=np.float32)]\n",
        "                aRec[-1][idx]=1\n",
        "            Y[seqLen]+=[aRec]\n",
        "\n",
        "        X[seqLen]=np.array(X[seqLen],dtype=np.float32)\n",
        "        X[seqLen]=np.reshape(X[seqLen],[X[seqLen].shape[0],X[seqLen].shape[1],1])\n",
        "        Y[seqLen]=np.array(Y[seqLen],dtype=np.float32)\n",
        "    return X,Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s6ZambmvF72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX,trainY=makeData(minSeqSize,maxSeqSize,batchSize,numOfBatches)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dsYIS0Terp0t",
        "outputId": "47a54d4e-4bf3-44a4-cb92-b43e3adabd04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Train X for',minSeqSize,':',trainX[minSeqSize].shape)\n",
        "print('Train Y for',minSeqSize,':',trainY[minSeqSize].shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train X for 3 : (4800, 3, 1)\n",
            "Train Y for 3 : (4800, 3, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxZ_7GwhvF79",
        "colab_type": "code",
        "outputId": "55e7f88f-2bae-4a2e-ce98-7bc6a96a2d19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "trainX[4][0]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.03815361],\n",
              "       [0.4298177 ],\n",
              "       [0.06307518],\n",
              "       [0.789144  ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSGtEbOWvF8A",
        "colab_type": "code",
        "outputId": "0764c3e0-5062-40d7-c1cd-6d2790809e3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "trainY[4][0]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "soZhrxTx6-Uy"
      },
      "source": [
        "### Pointer Network with Fast Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YkcI--KctfRn",
        "colab": {}
      },
      "source": [
        "class FastWeightsCell(tf.keras.Model):\n",
        "    def __init__(self,features=1, output_size=1,decay_rate = 0.9, learning_rate = 0.5, hidden_size=50):\n",
        "        super(FastWeightsCell, self).__init__()\n",
        "        self.DR = decay_rate\n",
        "        self.LR = learning_rate\n",
        "        self.features=features\n",
        "        self.output_size=output_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        \n",
        "        self.W_x = tf.Variable(tf.random_uniform([self.hidden_size,self.features], -np.sqrt(2/self.features), np.sqrt(2/self.features)), dtype=tf.float32)\n",
        "        self.B_x = tf.Variable(tf.zeros([self.hidden_size,1]), dtype=tf.float32)\n",
        "        self.W_h = tf.Variable(initial_value = 0.5 * np.identity(self.hidden_size), dtype = tf.float32)\n",
        "        self.W_y = tf.Variable(tf.random_uniform([self.output_size,self.hidden_size], -np.sqrt(2/self.hidden_size), np.sqrt(2/self.hidden_size)), dtype = tf.float32)\n",
        "        self.B_y = tf.Variable(tf.zeros([self.output_size,1]), dtype= tf.float32)\n",
        "        self.scale = tf.Variable(tf.ones([1,self.hidden_size,1]), dtype = tf.float32) \n",
        "        self.shift = tf.Variable(tf.zeros([1,self.hidden_size,1]), dtype = tf.float32)\n",
        "        \n",
        "        # values of A and H matricies\n",
        "        self.A = None  \n",
        "        self.H = None  \n",
        "\n",
        "    def call(self,X,H,A,S=1):\n",
        "\n",
        "        X = tf.cast(X, tf.float32)\n",
        "        self.H=H\n",
        "        self.A=A\n",
        "\n",
        "        # --- get new A ----\n",
        "        self.A = tf.scalar_mul(self.DR, self.A) + tf.scalar_mul(self.LR,(tf.matmul(H, tf.transpose(H,perm=[0,2,1]))))\n",
        "\n",
        "        broad_W_h=tf.broadcast_to(self.W_h,[self.H.shape[0].value,self.W_h.shape[0].value,self.W_h.shape[1].value])\n",
        "        broad_W_x=tf.broadcast_to(self.W_x,[self.H.shape[0].value,self.W_x.shape[0].value,self.W_x.shape[1].value])\n",
        "        H_s=tf.nn.relu(tf.matmul(broad_W_h,self.H)+tf.matmul(broad_W_x,X)        +     tf.expand_dims(self.B_x,0))\n",
        "\n",
        "\n",
        "        # --- get H_(s!=0) using W, previous_H, new A, H_s previous and applying normalization ---\n",
        "        for _ in range(S):\n",
        "            H_s=         tf.matmul(self.A,H_s)  +    tf.matmul(broad_W_h,self.H) + tf.matmul(broad_W_x,X)  +  tf.expand_dims(self.B_x,0)\n",
        "                    \n",
        "            # applying Layer Normalization \n",
        "            mean, var = tf.nn.moments(H_s, axes =0, keep_dims = True)\n",
        "            H_s = (self.scale*(H_s - mean))/(tf.sqrt(var + 1e-5) + self.shift)\n",
        "            \n",
        "            # applying non linearity\n",
        "            H_s = tf.nn.relu(H_s)\n",
        "        \n",
        "        self.H = H_s\n",
        "        broad_W_y=tf.broadcast_to(self.W_y,[self.H.shape[0].value,self.W_y.shape[0].value,self.W_y.shape[1].value])\n",
        "        output = tf.matmul(broad_W_y,self.H) + tf.expand_dims(self.B_y,0)\n",
        "\n",
        "        # --- return output, hidden state, and value of matrix A ---\n",
        "        return output, self.H, self.A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UpDh6QO-7d4a",
        "colab": {}
      },
      "source": [
        "class FWPointerNetwork(tf.keras.Model):\n",
        "    def __init__(self,features=1, output_size=None, hidden_size=50, fw_x_size=None, attentionInternalDim=None):\n",
        "        super(FWPointerNetwork, self).__init__()\n",
        "        self.features = features\n",
        "        self.output_size=output_size\n",
        "        if self.output_size is None:\n",
        "            self.output_size=features\n",
        "        self.hidden_size = hidden_size\n",
        "        self.attentionInternalDim=attentionInternalDim\n",
        "        if self.attentionInternalDim is None:\n",
        "            self.attentionInternalDim=self.hidden_size\n",
        "        self.fw_x_size=fw_x_size\n",
        "        if self.fw_x_size is None:\n",
        "            self.fw_x_size=self.hidden_size\n",
        "\n",
        "        # Encoder and Encoder Input\n",
        "        self.encodercell = FastWeightsCell(features=self.fw_x_size, output_size=self.output_size,hidden_size=self.hidden_size)\n",
        "        self.W_e = tf.Variable(tf.random_uniform([self.fw_x_size, self.features], -0.08, 0.08), dtype=tf.float32)    \n",
        "        self.B_e = tf.Variable(tf.random_uniform([self.fw_x_size, 1], -0.08, 0.08), dtype=tf.float32)\n",
        "\n",
        "        # Decoder and Decoder Input\n",
        "        self.decodercell = FastWeightsCell(features=self.fw_x_size, output_size=self.output_size,hidden_size=self.hidden_size)\n",
        "        self.W_d = tf.Variable(tf.random_uniform([self.fw_x_size, self.features], -0.08, 0.08), dtype=tf.float32)    \n",
        "        self.B_d = tf.Variable(tf.random_uniform([self.fw_x_size, 1], -0.08, 0.08), dtype=tf.float32)\n",
        "\n",
        "        # Attention Related Vector with bias\n",
        "        self.W1 = tf.Variable(tf.random_uniform([self.attentionInternalDim,self.hidden_size], -0.08, 0.08), dtype=tf.float32)\n",
        "        self.W2 = tf.Variable(tf.random_uniform([self.attentionInternalDim,self.hidden_size], -0.08, 0.08), dtype=tf.float32)\n",
        "        self.V = tf.Variable(tf.random_uniform([self.attentionInternalDim, 1], -0.5, 0.5), dtype=tf.float32)\n",
        "        self.B_ptr = tf.Variable(tf.random_uniform([self.attentionInternalDim,1], -0.08, 0.08), dtype=tf.float32)\n",
        "\n",
        "\n",
        "    def call(self, X):\n",
        "        givenbatchsize=X.shape[0].value\n",
        "        givenSeqLen=X.shape[1].value\n",
        "        eHstates = []\n",
        "        eH = tf.zeros([givenbatchsize, self.hidden_size,1],dtype=np.float32)\n",
        "        eA = tf.zeros([givenbatchsize, self.hidden_size,self.hidden_size],dtype=np.float32)\n",
        "        for i in range(givenSeqLen):            \n",
        "            # get batch's ith time step input\n",
        "            X_i = tf.transpose(X[:,i:i+1],[0,2,1])\n",
        "            broad_W_e=tf.broadcast_to(self.W_e,[givenbatchsize,self.W_e.shape[0].value,self.W_e.shape[1].value])\n",
        "            cell_input = tf.nn.elu(tf.matmul(broad_W_e,X_i) + tf.expand_dims(self.B_e,0))\n",
        "            _, eH,        eA        = self.encodercell(cell_input, eH, eA)\n",
        "            eHstates.append(eH)\n",
        "\n",
        "        dH = eHstates[-1]\n",
        "        dA = tf.zeros([givenbatchsize, self.hidden_size,self.hidden_size],dtype=np.float32)\n",
        "        X_i = tf.constant(-1,dtype=np.float32,shape=[givenbatchsize,self.features,1])\n",
        "        attentionVector_all=None\n",
        "        outputVector_all=None\n",
        "        identity=tf.eye(givenSeqLen,dtype=np.float32)\n",
        "        \n",
        "        for i in range(givenSeqLen):\n",
        "            \n",
        "            # -- apply the encoder dense layer to the batch --\n",
        "\n",
        "            broad_W_d=tf.broadcast_to(self.W_d,[givenbatchsize,self.W_d.shape[0].value,self.W_d.shape[1].value])\n",
        "\n",
        "            cell_input = tf.nn.elu(tf.matmul(broad_W_d,X_i) + tf.expand_dims(self.B_d,0))\n",
        "\n",
        "            _, dH,        dA        = self.decodercell(cell_input, dH, dA)\n",
        "            \n",
        "            # -- get the attention vector --\n",
        "            broad_W1 = tf.broadcast_to(self.W1,[givenbatchsize,self.W1.shape[0].value,self.W1.shape[1].value])            \n",
        "            broad_W2 = tf.broadcast_to(self.W2,[givenbatchsize,self.W2.shape[0].value,self.W2.shape[1].value])\n",
        "            broad_V = tf.broadcast_to(self.V,[givenbatchsize,self.V.shape[0].value,self.V.shape[1].value])\n",
        "            # get the decoder part of attention equation\n",
        "            d_part=tf.matmul(broad_W2,dH)            \n",
        "            # attention vector\n",
        "            attentionVector_i=None\n",
        "            \n",
        "            # components of attention vector based on components encoder\n",
        "            for encoderIndex in range(givenSeqLen):\n",
        "\n",
        "                attentionVector_component=tf.matmul(broad_W1,eHstates[encoderIndex])+ d_part     + tf.expand_dims(self.B_ptr,0)\n",
        "                attentionVector_component=tf.nn.elu(attentionVector_component)\n",
        "                attentionVector_component=tf.matmul(tf.transpose(broad_V,perm=[0,2,1]),attentionVector_component)\n",
        "                if attentionVector_i is None:\n",
        "                    attentionVector_i=attentionVector_component\n",
        "                else:\n",
        "                    attentionVector_i=tf.concat([attentionVector_i,attentionVector_component],axis=2)\n",
        "            attentionVector_i=tf.nn.softmax(attentionVector_i,axis=2)\n",
        "            \n",
        "            # overall attention vector for the batch x seqLen\n",
        "            if attentionVector_all is None:\n",
        "                attentionVector_all=attentionVector_i\n",
        "            else:\n",
        "                attentionVector_all=tf.concat(       [attentionVector_all  ,   attentionVector_i   ],axis=1)\n",
        "            \n",
        "            predictedOutput_i  =   tf.cast(tf.argmax(attentionVector_i,axis=2),dtype=np.int32)\n",
        "            extractionMatrix=tf.nn.embedding_lookup(identity,tf.reshape(predictedOutput_i,[predictedOutput_i.shape[0]]))\n",
        "            extractionMatrix=tf.expand_dims(extractionMatrix,axis=1)\n",
        "            X_i=tf.matmul(  tf.cast(extractionMatrix,dtype=np.float32) ,      X   )\n",
        "            if outputVector_all is None:\n",
        "                outputVector_all=X_i\n",
        "            else:\n",
        "                outputVector_all=tf.concat([outputVector_all,X_i],axis=1)\n",
        "            X_i=tf.transpose(X_i,[0,2,1])\n",
        "            # b x f x 1\n",
        "\n",
        "\n",
        "        return attentionVector_all,outputVector_all "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoPzn01j48ae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def runAndGetLoss(X,Y,model,isVerbose=0):\n",
        "\n",
        "    attn,output=model(X)\n",
        "    loss=tf.reduce_mean(tf.keras.backend.categorical_crossentropy(Y, attn))\n",
        "    loss=(loss/float(maxSeqSize-minSeqSize+1))\n",
        "    \n",
        "    if isVerbose>0:\n",
        "      for instance_idx in range(X.shape[0]):\n",
        "        print(\"====== Actual :\",np.reshape(X[instance_idx],X[instance_idx].shape[0]))\n",
        "        print('  - Predicted :',np.reshape(output[instance_idx],output[instance_idx].shape[0]))\n",
        "        print('\\n\\n')\n",
        "    \n",
        "    return attn,output,loss\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9qaIyvevF8c",
        "colab_type": "text"
      },
      "source": [
        "### Instantiate the Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYHI-KQKvF8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fwpn = FWPointerNetwork(features=trainX[minSeqSize][0].shape[1], output_size=trainX[minSeqSize][0].shape[1], hidden_size=hidden_dimensions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LkM2Lp_zq3VK"
      },
      "source": [
        "### Output of Network Before Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dum0ZXWSH9z2",
        "colab_type": "code",
        "outputId": "431912a4-cc93-49ed-bbba-da46c7cdde77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4947
        }
      },
      "source": [
        "# Use data point\n",
        "seqLen=minSeqSize\n",
        "attn,output,aloss=runAndGetLoss(trainX[seqLen][0:batchSize],trainY[seqLen][0:batchSize],fwpn,1)\n",
        "print(\"loss:\",aloss)\n",
        "print(\"attn:\")\n",
        "print(attn)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====== Actual : [0.37454012 0.9507143  0.7319939 ]\n",
            "  - Predicted : [0.9507143 0.9507143 0.9507143]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.5986585  0.15601864 0.15599452]\n",
            "  - Predicted : [0.15601864 0.15601864 0.15601864]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.05808361 0.8661761  0.601115  ]\n",
            "  - Predicted : [0.05808361 0.05808361 0.05808361]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.7080726  0.02058449 0.96990985]\n",
            "  - Predicted : [0.96990985 0.96990985 0.96990985]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.83244264 0.21233912 0.18182497]\n",
            "  - Predicted : [0.18182497 0.18182497 0.18182497]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.1834045  0.30424225 0.52475643]\n",
            "  - Predicted : [0.52475643 0.52475643 0.52475643]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.43194503 0.29122913 0.6118529 ]\n",
            "  - Predicted : [0.29122913 0.29122913 0.29122913]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.13949387 0.29214466 0.36636186]\n",
            "  - Predicted : [0.36636186 0.36636186 0.36636186]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.45606998 0.785176   0.19967379]\n",
            "  - Predicted : [0.785176 0.785176 0.785176]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.5142344  0.59241456 0.04645041]\n",
            "  - Predicted : [0.59241456 0.59241456 0.59241456]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.60754484 0.17052412 0.06505159]\n",
            "  - Predicted : [0.17052412 0.17052412 0.17052412]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.94888556 0.965632   0.80839735]\n",
            "  - Predicted : [0.94888556 0.94888556 0.94888556]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.30461377 0.09767211 0.684233  ]\n",
            "  - Predicted : [0.09767211 0.09767211 0.09767211]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.4401525  0.12203824 0.4951769 ]\n",
            "  - Predicted : [0.12203824 0.12203824 0.12203824]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.03438852 0.9093204  0.25877997]\n",
            "  - Predicted : [0.03438852 0.03438852 0.03438852]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.66252226 0.31171107 0.52006805]\n",
            "  - Predicted : [0.31171107 0.31171107 0.31171107]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.54671025 0.18485446 0.96958464]\n",
            "  - Predicted : [0.18485446 0.18485446 0.18485446]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.77513283 0.93949896 0.89482737]\n",
            "  - Predicted : [0.89482737 0.89482737 0.89482737]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.5979     0.9218742  0.08849251]\n",
            "  - Predicted : [0.9218742 0.9218742 0.9218742]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.19598286 0.04522729 0.32533032]\n",
            "  - Predicted : [0.32533032 0.32533032 0.32533032]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.3886773  0.27134904 0.8287375 ]\n",
            "  - Predicted : [0.27134904 0.27134904 0.27134904]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.35675332 0.2809345  0.54269606]\n",
            "  - Predicted : [0.2809345 0.2809345 0.2809345]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.14092423 0.802197   0.07455064]\n",
            "  - Predicted : [0.07455064 0.07455064 0.07455064]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.9868869  0.77224475 0.19871569]\n",
            "  - Predicted : [0.9868869 0.9868869 0.9868869]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.00552212 0.81546146 0.7068573 ]\n",
            "  - Predicted : [0.00552212 0.00552212 0.00552212]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.7290072  0.77127033 0.07404465]\n",
            "  - Predicted : [0.07404465 0.07404465 0.07404465]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.35846573 0.11586906 0.86310345]\n",
            "  - Predicted : [0.11586906 0.11586906 0.11586906]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.6232981  0.33089802 0.06355835]\n",
            "  - Predicted : [0.33089802 0.33089802 0.33089802]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.31098232 0.32518333 0.72960615]\n",
            "  - Predicted : [0.32518333 0.32518333 0.32518333]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.63755745 0.88721275 0.47221494]\n",
            "  - Predicted : [0.88721275 0.88721275 0.88721275]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.11959425 0.7132448  0.76078504]\n",
            "  - Predicted : [0.76078504 0.76078504 0.76078504]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.5612772 0.7709672 0.4937956]\n",
            "  - Predicted : [0.7709672 0.7709672 0.7709672]\n",
            "\n",
            "\n",
            "\n",
            "loss: tf.Tensor(0.42712787, shape=(), dtype=float32)\n",
            "attn:\n",
            "tf.Tensor(\n",
            "[[[0.2877684  0.35611582 0.35611582]\n",
            "  [0.2877684  0.35611582 0.35611582]\n",
            "  [0.2877684  0.35611582 0.35611582]]\n",
            "\n",
            " [[0.26245743 0.36877128 0.36877128]\n",
            "  [0.26245743 0.36877128 0.36877128]\n",
            "  [0.26245743 0.36877128 0.36877128]]\n",
            "\n",
            " [[0.56510395 0.09861245 0.33628362]\n",
            "  [0.56510395 0.09861245 0.33628362]\n",
            "  [0.56510395 0.09861245 0.33628362]]\n",
            "\n",
            " [[0.21259388 0.3834666  0.40393957]\n",
            "  [0.21259388 0.3834666  0.40393957]\n",
            "  [0.21259388 0.3834666  0.40393957]]\n",
            "\n",
            " [[0.20990202 0.21353734 0.5765606 ]\n",
            "  [0.20990202 0.21353734 0.5765606 ]\n",
            "  [0.20990202 0.21353734 0.5765606 ]]\n",
            "\n",
            " [[0.23845036 0.27554712 0.48600253]\n",
            "  [0.23845036 0.27554712 0.48600253]\n",
            "  [0.23845036 0.27554712 0.48600253]]\n",
            "\n",
            " [[0.31956643 0.3402168  0.3402168 ]\n",
            "  [0.31956643 0.3402168  0.3402168 ]\n",
            "  [0.31956643 0.3402168  0.3402168 ]]\n",
            "\n",
            " [[0.25431028 0.1655619  0.58012784]\n",
            "  [0.25431028 0.1655619  0.58012784]\n",
            "  [0.25431028 0.1655619  0.58012784]]\n",
            "\n",
            " [[0.33213016 0.3339349  0.3339349 ]\n",
            "  [0.33213016 0.3339349  0.3339349 ]\n",
            "  [0.33213016 0.3339349  0.3339349 ]]\n",
            "\n",
            " [[0.30573946 0.34713027 0.34713027]\n",
            "  [0.30573946 0.34713027 0.34713027]\n",
            "  [0.30573946 0.34713027 0.34713027]]\n",
            "\n",
            " [[0.25792938 0.3710353  0.3710353 ]\n",
            "  [0.25792938 0.3710353  0.3710353 ]\n",
            "  [0.25792938 0.3710353  0.3710353 ]]\n",
            "\n",
            " [[0.7169725  0.07654774 0.20647974]\n",
            "  [0.6828633  0.09023417 0.2269026 ]\n",
            "  [0.6828633  0.09023417 0.2269026 ]]\n",
            "\n",
            " [[0.25161302 0.3741935  0.3741935 ]\n",
            "  [0.25161302 0.3741935  0.3741935 ]\n",
            "  [0.25161302 0.3741935  0.3741935 ]]\n",
            "\n",
            " [[0.323842   0.338079   0.338079  ]\n",
            "  [0.323842   0.338079   0.338079  ]\n",
            "  [0.323842   0.338079   0.338079  ]]\n",
            "\n",
            " [[0.78342545 0.08656868 0.13000588]\n",
            "  [0.78659195 0.08557253 0.12783556]\n",
            "  [0.78659195 0.08557253 0.12783556]]\n",
            "\n",
            " [[0.23034611 0.38482693 0.38482693]\n",
            "  [0.23034611 0.38482693 0.38482693]\n",
            "  [0.23034611 0.38482693 0.38482693]]\n",
            "\n",
            " [[0.28910163 0.3554492  0.3554492 ]\n",
            "  [0.28910163 0.3554492  0.3554492 ]\n",
            "  [0.28910163 0.3554492  0.3554492 ]]\n",
            "\n",
            " [[0.2093998  0.30661258 0.48398757]\n",
            "  [0.2093998  0.30661258 0.48398757]\n",
            "  [0.2093998  0.30661258 0.48398757]]\n",
            "\n",
            " [[0.26284376 0.3685781  0.3685781 ]\n",
            "  [0.26284376 0.3685781  0.3685781 ]\n",
            "  [0.26284376 0.3685781  0.3685781 ]]\n",
            "\n",
            " [[0.23439439 0.30311403 0.4624916 ]\n",
            "  [0.23439439 0.30311403 0.4624916 ]\n",
            "  [0.23439439 0.30311403 0.4624916 ]]\n",
            "\n",
            " [[0.29547718 0.3522614  0.3522614 ]\n",
            "  [0.29547718 0.3522614  0.3522614 ]\n",
            "  [0.29547718 0.3522614  0.3522614 ]]\n",
            "\n",
            " [[0.27825943 0.36087027 0.36087027]\n",
            "  [0.27825943 0.36087027 0.36087027]\n",
            "  [0.27825943 0.36087027 0.36087027]]\n",
            "\n",
            " [[0.25119343 0.17787492 0.5709317 ]\n",
            "  [0.25119343 0.17787492 0.5709317 ]\n",
            "  [0.25119343 0.17787492 0.5709317 ]]\n",
            "\n",
            " [[0.9714886  0.02259139 0.00592005]\n",
            "  [0.97137994 0.02268413 0.00593588]\n",
            "  [0.97137916 0.02268481 0.00593599]]\n",
            "\n",
            " [[0.9669515  0.02870434 0.00434421]\n",
            "  [0.9669822  0.02870805 0.00430987]\n",
            "  [0.9669823  0.02870805 0.00430971]]\n",
            "\n",
            " [[0.21099398 0.36315048 0.42585564]\n",
            "  [0.21099398 0.36315048 0.42585564]\n",
            "  [0.21099398 0.36315048 0.42585564]]\n",
            "\n",
            " [[0.27916536 0.36041734 0.36041734]\n",
            "  [0.27916536 0.36041734 0.36041734]\n",
            "  [0.27916536 0.36041734 0.36041734]]\n",
            "\n",
            " [[0.2499413  0.37502936 0.37502936]\n",
            "  [0.2499413  0.37502936 0.37502936]\n",
            "  [0.2499413  0.37502936 0.37502936]]\n",
            "\n",
            " [[0.25476903 0.37261552 0.37261552]\n",
            "  [0.25476903 0.37261552 0.37261552]\n",
            "  [0.25476903 0.37261552 0.37261552]]\n",
            "\n",
            " [[0.24276395 0.37861803 0.37861803]\n",
            "  [0.24276395 0.37861803 0.37861803]\n",
            "  [0.24276395 0.37861803 0.37861803]]\n",
            "\n",
            " [[0.2559154  0.12990429 0.6141804 ]\n",
            "  [0.2559154  0.12990429 0.6141804 ]\n",
            "  [0.2559154  0.12990429 0.6141804 ]]\n",
            "\n",
            " [[0.2816167  0.35919166 0.35919166]\n",
            "  [0.2816167  0.35919166 0.35919166]\n",
            "  [0.2816167  0.35919166 0.35919166]]], shape=(32, 3, 3), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5YMQpvDvF8g",
        "colab_type": "text"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEJUt4aEvF8h",
        "colab_type": "text"
      },
      "source": [
        "##### Config Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZxbw-BKvF8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create batches of training data\n",
        "batchedDataset={}\n",
        "for seqLen in range(minSeqSize,maxSeqSize+1):\n",
        "    batchedDataset[seqLen]=[]\n",
        "    for aBatch in tf.data.Dataset.from_tensor_slices((trainX[seqLen],trainY[seqLen])).batch(batchSize):\n",
        "        batchedDataset[seqLen]+=[aBatch]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aog5pAPYvF8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create dev data and batches\n",
        "devBatchSize=64\n",
        "devX,devY=makeData(minSeqSize,maxSeqSize,devBatchSize,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48083hMdvF8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training configuration\n",
        "lastepoch=-1\n",
        "optimizer = tf.train.AdamOptimizer()\n",
        "loss_history = []\n",
        "wholeLoss_history=[]\n",
        "devLoss_history=[]\n",
        "total_attention = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVDN0tMzvF8l",
        "colab_type": "text"
      },
      "source": [
        "##### Run Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNUEbgorvF8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochsToRun = 5\n",
        "overfitFlag=False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "uzLakdiwvF8m",
        "colab_type": "code",
        "outputId": "176fec74-2caa-45a2-85dd-afd37b9c7c87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2754
        }
      },
      "source": [
        "for epoch in range(lastepoch+1,lastepoch+1+epochsToRun):\n",
        "    if overfitFlag:\n",
        "        break\n",
        "    lastepoch=epoch\n",
        "    print(\"New Epoch Started:\",epoch)\n",
        "    for batch in range(numOfBatches):\n",
        "        wholeLoss=0\n",
        "        for seqLen in range(minSeqSize,maxSeqSize+1):\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                # get data for this batch\n",
        "                input_data, target_data=batchedDataset[seqLen][batch]\n",
        "                # input_data -> (batch_size, input_sequence_length, input_dimension)\n",
        "                # target_data -> (batch_size, input_sequence_length, input_sequence_length)\n",
        "\n",
        "                # run the pointer network and get loss\n",
        "                _,_,batch_loss=runAndGetLoss(input_data,target_data,fwpn)\n",
        "            \n",
        "            # fetch the trainable variables\n",
        "            variables = fwpn.variables\n",
        "            \n",
        "            # calculate the gradient\n",
        "            grads = tape.gradient(batch_loss, variables)\n",
        "                        \n",
        "            # update the weights of the network\n",
        "            optimizer.apply_gradients(zip(grads, variables), global_step=tf.train.get_or_create_global_step())\n",
        "            \n",
        "            # store the loss history \n",
        "            loss_history.append(batch_loss.numpy())\n",
        "\n",
        "            # combined loss per output across batches of ALL seq sizes\n",
        "            wholeLoss+=batch_loss/float(maxSeqSize-minSeqSize+1)\n",
        "\n",
        "        # store the loss history \n",
        "        wholeLoss_history.append(wholeLoss.numpy())\n",
        "            \n",
        "        if batch % 10 == 0:\n",
        "            print(\"\\tEpoch {:03d}/{:03d}: Loss at batchSetNum {:02d}: {:.9f}\".format((epoch), epochsToRun-1, batch, wholeLoss),dt.now())\n",
        "\n",
        "            devLoss=0\n",
        "            for seqLen in range(minSeqSize,maxSeqSize+1):\n",
        "                _,_,interdevLoss=runAndGetLoss(devX[seqLen],devY[seqLen],fwpn)\n",
        "                devLoss+=interdevLoss/float(maxSeqSize-minSeqSize+1)\n",
        "            devLoss_history.append(devLoss.numpy())\n",
        "            print('\\t               WholeLoss:',np.round(wholeLoss.numpy(),5),'DevLoss:',np.round(devLoss,5))\n",
        "\n",
        "    print(\"Epoch {:03d}/{:03d} completed \\t - \\tLoss at batchSetNum {:02d}: {:.9f}\".format((epoch), epochsToRun-1, batch, wholeLoss),dt.now())\n",
        "print(\"Final loss: {:.9f}\".format(wholeLoss),dt.now())"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "New Epoch Started: 0\n",
            "\tEpoch 000/004: Loss at batchSetNum 00: 0.494494259 2019-05-04 20:50:22.469190\n",
            "\t               WholeLoss: 0.49449 DevLoss: 0.47204\n",
            "\tEpoch 000/004: Loss at batchSetNum 10: 0.454814970 2019-05-04 20:50:26.381139\n",
            "\t               WholeLoss: 0.45481 DevLoss: 0.45486\n",
            "\tEpoch 000/004: Loss at batchSetNum 20: 0.454199016 2019-05-04 20:50:30.111482\n",
            "\t               WholeLoss: 0.4542 DevLoss: 0.45477\n",
            "\tEpoch 000/004: Loss at batchSetNum 30: 0.454629600 2019-05-04 20:50:33.863497\n",
            "\t               WholeLoss: 0.45463 DevLoss: 0.4543\n",
            "\tEpoch 000/004: Loss at batchSetNum 40: 0.454117119 2019-05-04 20:50:37.601897\n",
            "\t               WholeLoss: 0.45412 DevLoss: 0.45562\n",
            "\tEpoch 000/004: Loss at batchSetNum 50: 0.471841991 2019-05-04 20:50:41.348765\n",
            "\t               WholeLoss: 0.47184 DevLoss: 0.46477\n",
            "\tEpoch 000/004: Loss at batchSetNum 60: 0.455596745 2019-05-04 20:50:45.103969\n",
            "\t               WholeLoss: 0.4556 DevLoss: 0.45495\n",
            "\tEpoch 000/004: Loss at batchSetNum 70: 0.454259902 2019-05-04 20:50:48.870624\n",
            "\t               WholeLoss: 0.45426 DevLoss: 0.45438\n",
            "\tEpoch 000/004: Loss at batchSetNum 80: 0.454256058 2019-05-04 20:50:52.620647\n",
            "\t               WholeLoss: 0.45426 DevLoss: 0.45419\n",
            "\tEpoch 000/004: Loss at batchSetNum 90: 0.455388188 2019-05-04 20:50:56.382289\n",
            "\t               WholeLoss: 0.45539 DevLoss: 0.45501\n",
            "\tEpoch 000/004: Loss at batchSetNum 100: 0.453250170 2019-05-04 20:51:00.128648\n",
            "\t               WholeLoss: 0.45325 DevLoss: 0.45346\n",
            "\tEpoch 000/004: Loss at batchSetNum 110: 0.453992903 2019-05-04 20:51:03.873927\n",
            "\t               WholeLoss: 0.45399 DevLoss: 0.45231\n",
            "\tEpoch 000/004: Loss at batchSetNum 120: 0.450336337 2019-05-04 20:51:07.628120\n",
            "\t               WholeLoss: 0.45034 DevLoss: 0.45154\n",
            "\tEpoch 000/004: Loss at batchSetNum 130: 0.450717986 2019-05-04 20:51:11.651583\n",
            "\t               WholeLoss: 0.45072 DevLoss: 0.45109\n",
            "\tEpoch 000/004: Loss at batchSetNum 140: 0.451252252 2019-05-04 20:51:15.950681\n",
            "\t               WholeLoss: 0.45125 DevLoss: 0.45258\n",
            "Epoch 000/004 completed \t - \tLoss at batchSetNum 149: 0.451101124 2019-05-04 20:51:19.857964\n",
            "New Epoch Started: 1\n",
            "\tEpoch 001/004: Loss at batchSetNum 00: 0.450377166 2019-05-04 20:51:20.233181\n",
            "\t               WholeLoss: 0.45038 DevLoss: 0.45207\n",
            "\tEpoch 001/004: Loss at batchSetNum 10: 0.452735364 2019-05-04 20:51:23.981195\n",
            "\t               WholeLoss: 0.45274 DevLoss: 0.45045\n",
            "\tEpoch 001/004: Loss at batchSetNum 20: 0.446763039 2019-05-04 20:51:27.732799\n",
            "\t               WholeLoss: 0.44676 DevLoss: 0.44938\n",
            "\tEpoch 001/004: Loss at batchSetNum 30: 0.454383314 2019-05-04 20:51:31.480172\n",
            "\t               WholeLoss: 0.45438 DevLoss: 0.44835\n",
            "\tEpoch 001/004: Loss at batchSetNum 40: 0.450417012 2019-05-04 20:51:35.224753\n",
            "\t               WholeLoss: 0.45042 DevLoss: 0.45454\n",
            "\tEpoch 001/004: Loss at batchSetNum 50: 0.448473632 2019-05-04 20:51:38.984299\n",
            "\t               WholeLoss: 0.44847 DevLoss: 0.44873\n",
            "\tEpoch 001/004: Loss at batchSetNum 60: 0.449815512 2019-05-04 20:51:42.742728\n",
            "\t               WholeLoss: 0.44982 DevLoss: 0.44903\n",
            "\tEpoch 001/004: Loss at batchSetNum 70: 0.448322356 2019-05-04 20:51:46.484003\n",
            "\t               WholeLoss: 0.44832 DevLoss: 0.44837\n",
            "\tEpoch 001/004: Loss at batchSetNum 80: 0.447115719 2019-05-04 20:51:50.259133\n",
            "\t               WholeLoss: 0.44712 DevLoss: 0.44695\n",
            "\tEpoch 001/004: Loss at batchSetNum 90: 0.448822826 2019-05-04 20:51:54.012354\n",
            "\t               WholeLoss: 0.44882 DevLoss: 0.44989\n",
            "\tEpoch 001/004: Loss at batchSetNum 100: 0.439919651 2019-05-04 20:51:57.784598\n",
            "\t               WholeLoss: 0.43992 DevLoss: 0.44655\n",
            "\tEpoch 001/004: Loss at batchSetNum 110: 0.450471967 2019-05-04 20:52:01.531563\n",
            "\t               WholeLoss: 0.45047 DevLoss: 0.44697\n",
            "\tEpoch 001/004: Loss at batchSetNum 120: 0.442351937 2019-05-04 20:52:05.273269\n",
            "\t               WholeLoss: 0.44235 DevLoss: 0.44673\n",
            "\tEpoch 001/004: Loss at batchSetNum 130: 0.448572338 2019-05-04 20:52:09.049613\n",
            "\t               WholeLoss: 0.44857 DevLoss: 0.44635\n",
            "\tEpoch 001/004: Loss at batchSetNum 140: 0.447163522 2019-05-04 20:52:12.808554\n",
            "\t               WholeLoss: 0.44716 DevLoss: 0.44689\n",
            "Epoch 001/004 completed \t - \tLoss at batchSetNum 149: 0.448368073 2019-05-04 20:52:16.193607\n",
            "New Epoch Started: 2\n",
            "\tEpoch 002/004: Loss at batchSetNum 00: 0.442072392 2019-05-04 20:52:16.566353\n",
            "\t               WholeLoss: 0.44207 DevLoss: 0.44538\n",
            "\tEpoch 002/004: Loss at batchSetNum 10: 0.452571869 2019-05-04 20:52:21.039313\n",
            "\t               WholeLoss: 0.45257 DevLoss: 0.44504\n",
            "\tEpoch 002/004: Loss at batchSetNum 20: 0.445749313 2019-05-04 20:52:25.711297\n",
            "\t               WholeLoss: 0.44575 DevLoss: 0.44897\n",
            "\tEpoch 002/004: Loss at batchSetNum 30: 0.456350863 2019-05-04 20:52:29.888384\n",
            "\t               WholeLoss: 0.45635 DevLoss: 0.44685\n",
            "\tEpoch 002/004: Loss at batchSetNum 40: 0.447264910 2019-05-04 20:52:34.187064\n",
            "\t               WholeLoss: 0.44726 DevLoss: 0.44616\n",
            "\tEpoch 002/004: Loss at batchSetNum 50: 0.446957648 2019-05-04 20:52:38.486115\n",
            "\t               WholeLoss: 0.44696 DevLoss: 0.44454\n",
            "\tEpoch 002/004: Loss at batchSetNum 60: 0.445839286 2019-05-04 20:52:42.423803\n",
            "\t               WholeLoss: 0.44584 DevLoss: 0.44544\n",
            "\tEpoch 002/004: Loss at batchSetNum 70: 0.449342191 2019-05-04 20:52:46.152735\n",
            "\t               WholeLoss: 0.44934 DevLoss: 0.44465\n",
            "\tEpoch 002/004: Loss at batchSetNum 80: 0.447309613 2019-05-04 20:52:49.919324\n",
            "\t               WholeLoss: 0.44731 DevLoss: 0.44652\n",
            "\tEpoch 002/004: Loss at batchSetNum 90: 0.446888864 2019-05-04 20:52:53.671516\n",
            "\t               WholeLoss: 0.44689 DevLoss: 0.44414\n",
            "\tEpoch 002/004: Loss at batchSetNum 100: 0.435690433 2019-05-04 20:52:57.486943\n",
            "\t               WholeLoss: 0.43569 DevLoss: 0.44268\n",
            "\tEpoch 002/004: Loss at batchSetNum 110: 0.445803821 2019-05-04 20:53:01.246493\n",
            "\t               WholeLoss: 0.4458 DevLoss: 0.44382\n",
            "\tEpoch 002/004: Loss at batchSetNum 120: 0.447460592 2019-05-04 20:53:04.984978\n",
            "\t               WholeLoss: 0.44746 DevLoss: 0.45211\n",
            "\tEpoch 002/004: Loss at batchSetNum 130: 0.447258711 2019-05-04 20:53:08.722663\n",
            "\t               WholeLoss: 0.44726 DevLoss: 0.44957\n",
            "\tEpoch 002/004: Loss at batchSetNum 140: 0.455369532 2019-05-04 20:53:12.485673\n",
            "\t               WholeLoss: 0.45537 DevLoss: 0.44797\n",
            "Epoch 002/004 completed \t - \tLoss at batchSetNum 149: 0.451481938 2019-05-04 20:53:15.865104\n",
            "New Epoch Started: 3\n",
            "\tEpoch 003/004: Loss at batchSetNum 00: 0.443702519 2019-05-04 20:53:16.245321\n",
            "\t               WholeLoss: 0.4437 DevLoss: 0.44298\n",
            "\tEpoch 003/004: Loss at batchSetNum 10: 0.454256654 2019-05-04 20:53:20.007676\n",
            "\t               WholeLoss: 0.45426 DevLoss: 0.44065\n",
            "\tEpoch 003/004: Loss at batchSetNum 20: 0.437590420 2019-05-04 20:53:23.762250\n",
            "\t               WholeLoss: 0.43759 DevLoss: 0.43998\n",
            "\tEpoch 003/004: Loss at batchSetNum 30: 0.448638082 2019-05-04 20:53:27.506967\n",
            "\t               WholeLoss: 0.44864 DevLoss: 0.44008\n",
            "\tEpoch 003/004: Loss at batchSetNum 40: 0.439245284 2019-05-04 20:53:31.521127\n",
            "\t               WholeLoss: 0.43925 DevLoss: 0.44118\n",
            "\tEpoch 003/004: Loss at batchSetNum 50: 0.441660643 2019-05-04 20:53:35.880953\n",
            "\t               WholeLoss: 0.44166 DevLoss: 0.43791\n",
            "\tEpoch 003/004: Loss at batchSetNum 60: 0.446045339 2019-05-04 20:53:39.657032\n",
            "\t               WholeLoss: 0.44605 DevLoss: 0.438\n",
            "\tEpoch 003/004: Loss at batchSetNum 70: 0.448069572 2019-05-04 20:53:43.410535\n",
            "\t               WholeLoss: 0.44807 DevLoss: 0.43977\n",
            "\tEpoch 003/004: Loss at batchSetNum 80: 0.441429734 2019-05-04 20:53:47.155773\n",
            "\t               WholeLoss: 0.44143 DevLoss: 0.43797\n",
            "\tEpoch 003/004: Loss at batchSetNum 90: 0.431809425 2019-05-04 20:53:51.017172\n",
            "\t               WholeLoss: 0.43181 DevLoss: 0.43491\n",
            "\tEpoch 003/004: Loss at batchSetNum 100: 0.434624732 2019-05-04 20:53:55.325258\n",
            "\t               WholeLoss: 0.43462 DevLoss: 0.43261\n",
            "\tEpoch 003/004: Loss at batchSetNum 110: 0.438715219 2019-05-04 20:53:59.639864\n",
            "\t               WholeLoss: 0.43872 DevLoss: 0.43927\n",
            "\tEpoch 003/004: Loss at batchSetNum 120: 0.432622492 2019-05-04 20:54:03.476713\n",
            "\t               WholeLoss: 0.43262 DevLoss: 0.4301\n",
            "\tEpoch 003/004: Loss at batchSetNum 130: 0.433265626 2019-05-04 20:54:07.218854\n",
            "\t               WholeLoss: 0.43327 DevLoss: 0.43091\n",
            "\tEpoch 003/004: Loss at batchSetNum 140: 0.451155722 2019-05-04 20:54:10.986481\n",
            "\t               WholeLoss: 0.45116 DevLoss: 0.44035\n",
            "Epoch 003/004 completed \t - \tLoss at batchSetNum 149: 0.448836207 2019-05-04 20:54:14.384037\n",
            "New Epoch Started: 4\n",
            "\tEpoch 004/004: Loss at batchSetNum 00: 0.433148682 2019-05-04 20:54:14.756219\n",
            "\t               WholeLoss: 0.43315 DevLoss: 0.42964\n",
            "\tEpoch 004/004: Loss at batchSetNum 10: 0.440931737 2019-05-04 20:54:18.491716\n",
            "\t               WholeLoss: 0.44093 DevLoss: 0.42879\n",
            "\tEpoch 004/004: Loss at batchSetNum 20: 0.425656676 2019-05-04 20:54:22.245463\n",
            "\t               WholeLoss: 0.42566 DevLoss: 0.42631\n",
            "\tEpoch 004/004: Loss at batchSetNum 30: 0.435180187 2019-05-04 20:54:25.991356\n",
            "\t               WholeLoss: 0.43518 DevLoss: 0.42444\n",
            "\tEpoch 004/004: Loss at batchSetNum 40: 0.428937435 2019-05-04 20:54:29.753680\n",
            "\t               WholeLoss: 0.42894 DevLoss: 0.42761\n",
            "\tEpoch 004/004: Loss at batchSetNum 50: 0.436246216 2019-05-04 20:54:33.481485\n",
            "\t               WholeLoss: 0.43625 DevLoss: 0.44224\n",
            "\tEpoch 004/004: Loss at batchSetNum 60: 0.432692587 2019-05-04 20:54:37.296141\n",
            "\t               WholeLoss: 0.43269 DevLoss: 0.4326\n",
            "\tEpoch 004/004: Loss at batchSetNum 70: 0.429962873 2019-05-04 20:54:41.071919\n",
            "\t               WholeLoss: 0.42996 DevLoss: 0.4258\n",
            "\tEpoch 004/004: Loss at batchSetNum 80: 0.421490312 2019-05-04 20:54:44.813075\n",
            "\t               WholeLoss: 0.42149 DevLoss: 0.41978\n",
            "\tEpoch 004/004: Loss at batchSetNum 90: 0.414424837 2019-05-04 20:54:48.555246\n",
            "\t               WholeLoss: 0.41442 DevLoss: 0.42248\n",
            "\tEpoch 004/004: Loss at batchSetNum 100: 0.403581858 2019-05-04 20:54:52.325079\n",
            "\t               WholeLoss: 0.40358 DevLoss: 0.42257\n",
            "\tEpoch 004/004: Loss at batchSetNum 110: 0.423942029 2019-05-04 20:54:56.058653\n",
            "\t               WholeLoss: 0.42394 DevLoss: 0.41961\n",
            "\tEpoch 004/004: Loss at batchSetNum 120: 0.427053034 2019-05-04 20:54:59.783968\n",
            "\t               WholeLoss: 0.42705 DevLoss: 0.43692\n",
            "\tEpoch 004/004: Loss at batchSetNum 130: 0.425687253 2019-05-04 20:55:03.528051\n",
            "\t               WholeLoss: 0.42569 DevLoss: 0.4217\n",
            "\tEpoch 004/004: Loss at batchSetNum 140: 0.419941753 2019-05-04 20:55:07.250710\n",
            "\t               WholeLoss: 0.41994 DevLoss: 0.42117\n",
            "Epoch 004/004 completed \t - \tLoss at batchSetNum 149: 0.439215809 2019-05-04 20:55:10.657083\n",
            "Final loss: 0.439215809 2019-05-04 20:55:10.657964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0GCUvlzuXxya"
      },
      "source": [
        "### Loss plot over the entire training sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "miigFwpMW_lO",
        "outputId": "ec095a5e-1fbe-4caa-f569-6378f837034b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.plot(loss_history)\n",
        "plt.ylabel('loss value')\n",
        "plt.xlabel('batches')\n",
        "plt.show()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiKe/w86MIcc76uopgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ySe7cdhArp1K",
        "outputId": "783dfaf0-f18f-4f9d-ef34-746866957332",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.plot(wholeLoss_history)\n",
        "plt.ylabel('wholeLoss value')\n",
        "plt.xlabel('batches')\n",
        "plt.show()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nt79uwKoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nR8v-8CYrp1M",
        "outputId": "d917cff0-4227-4dcf-942a-084d0cd1dcd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.plot(devLoss_history)\n",
        "plt.ylabel('devLoss value')\n",
        "plt.xlabel('batches')\n",
        "plt.show()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3D8wqL9Rrp1O"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gj8KZRWIrp1O",
        "outputId": "2eabc440-41ad-4eaf-801f-a19cd04a928a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# print 1\n",
        "aloss=0\n",
        "print(\"SUMMARY\")\n",
        "for seqLen in range(minSeqSize,maxSeqSize+1+5):\n",
        "  if seqLen==maxSeqSize+1:\n",
        "    print('---')\n",
        "  X,Y=makeData(seqLen,seqLen,50,1)\n",
        "  _,_,interdevLoss=runAndGetLoss(X[seqLen],Y[seqLen],fwpn)\n",
        "  aloss+=interdevLoss/float(maxSeqSize-minSeqSize+1)\n",
        "  print('Seq:',seqLen,'Size:',X[seqLen].shape[0],'loss:',aloss.numpy())\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SUMMARY\n",
            "Seq: 3 Size: 50 loss: 0.11700639\n",
            "Seq: 4 Size: 50 loss: 0.25899863\n",
            "Seq: 5 Size: 50 loss: 0.42547652\n",
            "---\n",
            "Seq: 6 Size: 50 loss: 0.61819184\n",
            "Seq: 7 Size: 50 loss: 0.8349714\n",
            "Seq: 8 Size: 50 loss: 1.0666623\n",
            "Seq: 9 Size: 50 loss: 1.319737\n",
            "Seq: 10 Size: 50 loss: 1.5850308\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBX33JKWKgpm",
        "colab_type": "code",
        "outputId": "3689416e-1ff1-4d96-de5c-c7d355d0980d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 41429
        }
      },
      "source": [
        "# print 2\n",
        "print(\"DETAILED\")\n",
        "for seqLen in range(minSeqSize,maxSeqSize+1+5):\n",
        "  print()\n",
        "  if seqLen==maxSeqSize+1:\n",
        "      print('*********************************************************************************************************************************************')\n",
        "  print()\n",
        "  X,Y=makeData(seqLen,seqLen,50,1)\n",
        "  print('Seq:',seqLen,'Size:',X[seqLen].shape[0])\n",
        "  print('--------------------------------------------------------------------------------------------------------------------------------------------')\n",
        "  _,_,interdevLoss=runAndGetLoss(X[seqLen],Y[seqLen],fwpn,1)\n",
        "  aloss+=interdevLoss/float(maxSeqSize-minSeqSize+1)\n",
        "  print('loss:',aloss.numpy())"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DETAILED\n",
            "\n",
            "\n",
            "Seq: 3 Size: 50\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------\n",
            "====== Actual : [0.10679921 0.14326723 0.3152445 ]\n",
            "  - Predicted : [0.10679921 0.14326723 0.3152445 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.45148468 0.1933501  0.755625  ]\n",
            "  - Predicted : [0.755625   0.45148468 0.45148468]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.19332437 0.12412645 0.9945549 ]\n",
            "  - Predicted : [0.19332437 0.19332437 0.9945549 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.44771156 0.17000702 0.89455694]\n",
            "  - Predicted : [0.89455694 0.44771156 0.44771156]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.23109162 0.92557997 0.11896085]\n",
            "  - Predicted : [0.23109162 0.23109162 0.92557997]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.8418147 0.1842671 0.9383376]\n",
            "  - Predicted : [0.9383376 0.9383376 0.9383376]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.57424366 0.18991369 0.8448201 ]\n",
            "  - Predicted : [0.8448201 0.8448201 0.8448201]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.390576  0.7328134 0.6434407]\n",
            "  - Predicted : [0.7328134 0.390576  0.6434407]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.7142945 0.3437149 0.9388255]\n",
            "  - Predicted : [0.3437149 0.3437149 0.7142945]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.55981314 0.07756061 0.06673401]\n",
            "  - Predicted : [0.06673401 0.06673401 0.06673401]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.73822963 0.84997445 0.69527966]\n",
            "  - Predicted : [0.69527966 0.69527966 0.73822963]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.27749732 0.22590396 0.5654366 ]\n",
            "  - Predicted : [0.27749732 0.27749732 0.5654366 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.1967795  0.37909976 0.62869126]\n",
            "  - Predicted : [0.1967795  0.1967795  0.62869126]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.28491133 0.37543893 0.3605179 ]\n",
            "  - Predicted : [0.28491133 0.28491133 0.3605179 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.46052352 0.6743598  0.78234917]\n",
            "  - Predicted : [0.6743598  0.46052352 0.46052352]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.66508245 0.02616783 0.8968397 ]\n",
            "  - Predicted : [0.8968397  0.02616783 0.66508245]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.5811888 0.9202465 0.9638723]\n",
            "  - Predicted : [0.9638723 0.9202465 0.9202465]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.46784678 0.9163656  0.36538565]\n",
            "  - Predicted : [0.9163656  0.46784678 0.46784678]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.26037824 0.07363027 0.45183045]\n",
            "  - Predicted : [0.26037824 0.26037824 0.45183045]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.68868726 0.97683567 0.52130926]\n",
            "  - Predicted : [0.97683567 0.97683567 0.97683567]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.73447484 0.89614713 0.5431853 ]\n",
            "  - Predicted : [0.5431853  0.5431853  0.73447484]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.16676529 0.8482084  0.5741737 ]\n",
            "  - Predicted : [0.16676529 0.16676529 0.5741737 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.75851125 0.6584779  0.06103751]\n",
            "  - Predicted : [0.06103751 0.6584779  0.06103751]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.16911496 0.28624976 0.2847078 ]\n",
            "  - Predicted : [0.16911496 0.16911496 0.2847078 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.8391977  0.59823936 0.08337533]\n",
            "  - Predicted : [0.08337533 0.59823936 0.08337533]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.38719857 0.5563307  0.25150284]\n",
            "  - Predicted : [0.38719857 0.38719857 0.25150284]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.0398339  0.38026375 0.4611889 ]\n",
            "  - Predicted : [0.0398339  0.38026375 0.38026375]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.90476495 0.90836614 0.50040245]\n",
            "  - Predicted : [0.50040245 0.50040245 0.90476495]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.47149456 0.64050204 0.25812405]\n",
            "  - Predicted : [0.64050204 0.47149456 0.47149456]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.28571418 0.00255785 0.07821187]\n",
            "  - Predicted : [0.28571418 0.28571418 0.07821187]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.17850363 0.6405727  0.21265726]\n",
            "  - Predicted : [0.17850363 0.17850363 0.21265726]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.124079  0.6163047 0.65175  ]\n",
            "  - Predicted : [0.124079  0.6163047 0.65175  ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.05967313 0.7728981  0.60615706]\n",
            "  - Predicted : [0.05967313 0.60615706 0.60615706]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.39706543 0.9831823  0.01019935]\n",
            "  - Predicted : [0.9831823  0.39706543 0.01019935]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.5448517  0.1597034  0.32933277]\n",
            "  - Predicted : [0.32933277 0.32933277 0.5448517 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.13320228 0.6682145  0.4015716 ]\n",
            "  - Predicted : [0.13320228 0.4015716  0.4015716 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.9862995 0.6538471 0.9173348]\n",
            "  - Predicted : [0.9173348 0.9173348 0.9862995]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.24082719 0.31878406 0.36268225]\n",
            "  - Predicted : [0.24082719 0.24082719 0.36268225]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.83851504 0.21167576 0.9467208 ]\n",
            "  - Predicted : [0.9467208 0.9467208 0.9467208]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.04357909 0.889858   0.45141387]\n",
            "  - Predicted : [0.04357909 0.45141387 0.889858  ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.52589804 0.9973974  0.870048  ]\n",
            "  - Predicted : [0.870048 0.870048 0.870048]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.90402156 0.585535   0.9563418 ]\n",
            "  - Predicted : [0.9563418  0.9563418  0.90402156]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.6878054  0.81932706 0.7209339 ]\n",
            "  - Predicted : [0.81932706 0.81932706 0.7209339 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.7809144 0.637971  0.7264086]\n",
            "  - Predicted : [0.7264086 0.7264086 0.7809144]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.43593848 0.7068674  0.27681056]\n",
            "  - Predicted : [0.7068674  0.43593848 0.43593848]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.6349408  0.52375245 0.89853764]\n",
            "  - Predicted : [0.89853764 0.52375245 0.6349408 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.67322284 0.59662056 0.3130741 ]\n",
            "  - Predicted : [0.59662056 0.59662056 0.67322284]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.86280394 0.05415769 0.899751  ]\n",
            "  - Predicted : [0.899751 0.899751 0.899751]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.6529776 0.1894926 0.9029955]\n",
            "  - Predicted : [0.9029955 0.1894926 0.6529776]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.32635397 0.1682726  0.31914607]\n",
            "  - Predicted : [0.1682726  0.32635397 0.31914607]\n",
            "\n",
            "\n",
            "\n",
            "loss: 1.6982266\n",
            "\n",
            "\n",
            "Seq: 4 Size: 50\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------\n",
            "====== Actual : [0.9610723  0.7527585  0.9167931  0.29887202]\n",
            "  - Predicted : [0.7527585  0.29887202 0.9610723  0.9610723 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.08243928 0.5627552  0.4830008  0.7206048 ]\n",
            "  - Predicted : [0.08243928 0.4830008  0.7206048  0.7206048 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.5426752  0.39646676 0.00468585 0.46774656]\n",
            "  - Predicted : [0.46774656 0.46774656 0.5426752  0.5426752 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.12064282 0.9220011  0.9217063  0.803649  ]\n",
            "  - Predicted : [0.12064282 0.12064282 0.9217063  0.803649  ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.15786667 0.14743881 0.5633102  0.72746176]\n",
            "  - Predicted : [0.15786667 0.15786667 0.72746176 0.72746176]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.9045393  0.8940344  0.15532757 0.9954739 ]\n",
            "  - Predicted : [0.9954739 0.9045393 0.9954739 0.9954739]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.15679748 0.8401182  0.58694553 0.6782865 ]\n",
            "  - Predicted : [0.15679748 0.15679748 0.6782865  0.6782865 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.6039718  0.869682   0.63709766 0.8486638 ]\n",
            "  - Predicted : [0.63709766 0.6039718  0.6039718  0.6039718 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.15436798 0.8667067  0.9929533  0.6615068 ]\n",
            "  - Predicted : [0.15436798 0.15436798 0.8667067  0.6615068 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.9763611  0.21988353 0.8292831  0.16904698]\n",
            "  - Predicted : [0.8292831  0.16904698 0.9763611  0.9763611 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.51594275 0.66403496 0.6602622  0.67086095]\n",
            "  - Predicted : [0.67086095 0.51594275 0.51594275 0.67086095]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.3209247  0.9737211  0.00655299 0.62099844]\n",
            "  - Predicted : [0.9737211  0.3209247  0.62099844 0.62099844]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.8661097  0.8911132  0.7202054  0.57481223]\n",
            "  - Predicted : [0.57481223 0.7202054  0.8661097  0.7202054 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.45733505 0.449516   0.42509913 0.69989264]\n",
            "  - Predicted : [0.69989264 0.45733505 0.45733505 0.69989264]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.73120844 0.51476234 0.74081177 0.5284552 ]\n",
            "  - Predicted : [0.74081177 0.73120844 0.51476234 0.73120844]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.0973517  0.8516151  0.8704805  0.26646122]\n",
            "  - Predicted : [0.0973517  0.26646122 0.26646122 0.26646122]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.7864334  0.511171   0.12402718 0.3979987 ]\n",
            "  - Predicted : [0.511171  0.511171  0.7864334 0.7864334]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.07655196 0.786467   0.19623347 0.1643919 ]\n",
            "  - Predicted : [0.07655196 0.19623347 0.19623347 0.19623347]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.20853764 0.226131   0.67395216 0.638601  ]\n",
            "  - Predicted : [0.20853764 0.20853764 0.67395216 0.67395216]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.12933663 0.7244192  0.3490571  0.45747274]\n",
            "  - Predicted : [0.12933663 0.3490571  0.7244192  0.7244192 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.12485996 0.70862603 0.37622213 0.6321296 ]\n",
            "  - Predicted : [0.12485996 0.37622213 0.6321296  0.6321296 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.42722094 0.0488688  0.70348954 0.5525082 ]\n",
            "  - Predicted : [0.70348954 0.42722094 0.42722094 0.5525082 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.43424493 0.20155199 0.6243432  0.27519745]\n",
            "  - Predicted : [0.6243432  0.43424493 0.43424493 0.27519745]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.4291743  0.05648515 0.7767465  0.09003709]\n",
            "  - Predicted : [0.7767465  0.4291743  0.4291743  0.09003709]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.89083964 0.86757463 0.9710899  0.90844125]\n",
            "  - Predicted : [0.90844125 0.89083964 0.90844125 0.90844125]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.97140765 0.88727623 0.1125086  0.43768185]\n",
            "  - Predicted : [0.1125086  0.88727623 0.88727623 0.97140765]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.07615636 0.5452982  0.5297568  0.9221784 ]\n",
            "  - Predicted : [0.07615636 0.5297568  0.9221784  0.9221784 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.96969473 0.25964406 0.5823128  0.46444178]\n",
            "  - Predicted : [0.25964406 0.46444178 0.96969473 0.96969473]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.54673517 0.5317281  0.9141244  0.8961258 ]\n",
            "  - Predicted : [0.9141244  0.54673517 0.54673517 0.8961258 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.12273668 0.34511018 0.7527751  0.6839871 ]\n",
            "  - Predicted : [0.12273668 0.34511018 0.7527751  0.7527751 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.63119256 0.9938104  0.33693504 0.5152487 ]\n",
            "  - Predicted : [0.9938104  0.63119256 0.5152487  0.63119256]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.97915035 0.6955523  0.64868027 0.15474723]\n",
            "  - Predicted : [0.15474723 0.15474723 0.64868027 0.6955523 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.24665691 0.37747318 0.4648471  0.49721023]\n",
            "  - Predicted : [0.24665691 0.24665691 0.49721023 0.49721023]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.90213716 0.10721198 0.24835257 0.1436338 ]\n",
            "  - Predicted : [0.1436338  0.10721198 0.90213716 0.90213716]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.73531073 0.9705798  0.8939608  0.72330076]\n",
            "  - Predicted : [0.8939608  0.73531073 0.9705798  0.9705798 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.02152281 0.34703088 0.8636181  0.6530703 ]\n",
            "  - Predicted : [0.02152281 0.34703088 0.34703088 0.6530703 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.20960133 0.46648714 0.08791813 0.52080154]\n",
            "  - Predicted : [0.20960133 0.20960133 0.52080154 0.52080154]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.90102845 0.03871885 0.61389154 0.2331027 ]\n",
            "  - Predicted : [0.2331027  0.03871885 0.90102845 0.90102845]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.99038506 0.06510172 0.6172914  0.2563707 ]\n",
            "  - Predicted : [0.2563707  0.2563707  0.99038506 0.99038506]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.88246304 0.1219298  0.42925262 0.18536155]\n",
            "  - Predicted : [0.18536155 0.1219298  0.88246304 0.88246304]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.7994437  0.35144356 0.1867132  0.72590107]\n",
            "  - Predicted : [0.35144356 0.35144356 0.7994437  0.7994437 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.8172173  0.4623955  0.37884942 0.6321442 ]\n",
            "  - Predicted : [0.37884942 0.4623955  0.8172173  0.8172173 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.6513966  0.6607454  0.27575764 0.9413025 ]\n",
            "  - Predicted : [0.27575764 0.27575764 0.6513966  0.6513966 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.21344425 0.37415826 0.28369394 0.9311235 ]\n",
            "  - Predicted : [0.21344425 0.21344425 0.9311235  0.9311235 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.82837015 0.81127197 0.00471008 0.6859005 ]\n",
            "  - Predicted : [0.6859005  0.00471008 0.82837015 0.82837015]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.2302737  0.96774423 0.5307514  0.564703  ]\n",
            "  - Predicted : [0.2302737  0.2302737  0.96774423 0.96774423]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.35648283 0.53673065 0.7497372  0.56192017]\n",
            "  - Predicted : [0.53673065 0.35648283 0.56192017 0.56192017]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.6412629  0.47246808 0.7163997  0.899559  ]\n",
            "  - Predicted : [0.7163997 0.6412629 0.6412629 0.6412629]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.0510512  0.10729653 0.6856091  0.3777044 ]\n",
            "  - Predicted : [0.0510512  0.10729653 0.10729653 0.10729653]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.28161845 0.17859328 0.5726363  0.3475324 ]\n",
            "  - Predicted : [0.28161845 0.28161845 0.5726363  0.5726363 ]\n",
            "\n",
            "\n",
            "\n",
            "loss: 1.8351309\n",
            "\n",
            "\n",
            "Seq: 5 Size: 50\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------\n",
            "====== Actual : [0.5079608  0.95856124 0.75826764 0.7959509  0.1241979 ]\n",
            "  - Predicted : [0.75826764 0.1241979  0.5079608  0.75826764 0.75826764]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.32498032 0.10623547 0.96852094 0.6821876  0.01923384]\n",
            "  - Predicted : [0.10623547 0.32498032 0.96852094 0.96852094 0.96852094]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.47550482 0.26352564 0.53995883 0.17865768 0.05685549]\n",
            "  - Predicted : [0.53995883 0.05685549 0.47550482 0.17865768 0.17865768]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.32317755 0.2955071  0.7169636  0.47454885 0.2913278 ]\n",
            "  - Predicted : [0.2955071  0.32317755 0.7169636  0.7169636  0.7169636 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.5704305  0.07131739 0.6623526  0.14728937 0.27969936]\n",
            "  - Predicted : [0.6623526  0.07131739 0.5704305  0.6623526  0.6623526 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.28212288 0.46585193 0.95315737 0.32465926 0.28132188]\n",
            "  - Predicted : [0.46585193 0.95315737 0.95315737 0.95315737 0.95315737]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.16880198 0.3919689  0.18204111 0.13776934 0.85735863]\n",
            "  - Predicted : [0.16880198 0.3919689  0.85735863 0.85735863 0.85735863]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.05263874 0.71082515 0.2025709  0.01171502 0.795145  ]\n",
            "  - Predicted : [0.05263874 0.01171502 0.71082515 0.795145   0.795145  ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.7022855  0.3342989  0.07933253 0.36067155 0.18132758]\n",
            "  - Predicted : [0.3342989  0.07933253 0.7022855  0.7022855  0.7022855 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.9325036  0.5296231  0.96384364 0.35131413 0.5564628 ]\n",
            "  - Predicted : [0.5564628 0.5564628 0.9325036 0.9325036 0.9325036]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.19012342 0.8084291  0.04110031 0.6956154  0.3916601 ]\n",
            "  - Predicted : [0.19012342 0.19012342 0.8084291  0.6956154  0.6956154 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.57841575 0.5922591  0.7107951  0.2042622  0.5313859 ]\n",
            "  - Predicted : [0.7107951  0.5922591  0.57841575 0.7107951  0.7107951 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.42692593 0.2821811  0.49572784 0.95201504 0.94888496]\n",
            "  - Predicted : [0.95201504 0.42692593 0.94888496 0.94888496 0.94888496]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.27881733 0.8842072  0.8767548  0.24958465 0.59895074]\n",
            "  - Predicted : [0.8842072 0.8767548 0.8767548 0.8767548 0.8767548]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.86993575 0.5149948  0.36976945 0.65078545 0.17242506]\n",
            "  - Predicted : [0.17242506 0.17242506 0.86993575 0.86993575 0.86993575]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.16173138 0.83264613 0.04187492 0.80363    0.29049414]\n",
            "  - Predicted : [0.16173138 0.16173138 0.83264613 0.80363    0.80363   ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.4831225  0.543515   0.7670693  0.88385797 0.80422413]\n",
            "  - Predicted : [0.7670693  0.80422413 0.80422413 0.88385797 0.88385797]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.57234377 0.34801367 0.5265578  0.03002168 0.24498011]\n",
            "  - Predicted : [0.5265578  0.34801367 0.57234377 0.5265578  0.5265578 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.36615536 0.3197545  0.09514694 0.05075408 0.42071477]\n",
            "  - Predicted : [0.42071477 0.36615536 0.42071477 0.42071477 0.42071477]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.07479975 0.28620806 0.47482565 0.20996127 0.07953493]\n",
            "  - Predicted : [0.07479975 0.20996127 0.47482565 0.47482565 0.47482565]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.43213326 0.4484765  0.9156143  0.12783764 0.61499536]\n",
            "  - Predicted : [0.9156143  0.43213326 0.61499536 0.61499536 0.61499536]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.31970257 0.12359783 0.3931471  0.4279376  0.36356452]\n",
            "  - Predicted : [0.12359783 0.31970257 0.36356452 0.36356452 0.36356452]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.76573277 0.83920646 0.14873177 0.16790508 0.4212176 ]\n",
            "  - Predicted : [0.16790508 0.16790508 0.76573277 0.76573277 0.76573277]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.32018897 0.8195736  0.9968112  0.18111037 0.76254416]\n",
            "  - Predicted : [0.8195736  0.76254416 0.76254416 0.76254416 0.76254416]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.6072468  0.6444241  0.26444146 0.09719622 0.5432561 ]\n",
            "  - Predicted : [0.26444146 0.26444146 0.6072468  0.6072468  0.5432561 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.61350584 0.96304893 0.67523104 0.4436843  0.99400115]\n",
            "  - Predicted : [0.67523104 0.96304893 0.61350584 0.61350584 0.67523104]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.37323898 0.1625585  0.61798006 0.26625064 0.92220485]\n",
            "  - Predicted : [0.92220485 0.37323898 0.92220485 0.92220485 0.92220485]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.42786837 0.14961635 0.14163058 0.6496394  0.3658973 ]\n",
            "  - Predicted : [0.6496394  0.42786837 0.3658973  0.3658973  0.3658973 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.36372456 0.61232394 0.22151187 0.14542826 0.6572625 ]\n",
            "  - Predicted : [0.61232394 0.36372456 0.6572625  0.6572625  0.6572625 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.00523704 0.90736496 0.18297093 0.44785607 0.21147853]\n",
            "  - Predicted : [0.00523704 0.21147853 0.21147853 0.21147853 0.21147853]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.21821967 0.83500135 0.58503354 0.31145033 0.25109872]\n",
            "  - Predicted : [0.21821967 0.21821967 0.83500135 0.83500135 0.83500135]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.21286245 0.55444837 0.7307894  0.25352737 0.3323006 ]\n",
            "  - Predicted : [0.21286245 0.55444837 0.7307894  0.7307894  0.7307894 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.7203656  0.73727804 0.20732315 0.38220233 0.86995775]\n",
            "  - Predicted : [0.20732315 0.20732315 0.7203656  0.7203656  0.7203656 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.74019223 0.16249533 0.38596293 0.9732938  0.52537763]\n",
            "  - Predicted : [0.9732938  0.38596293 0.74019223 0.74019223 0.74019223]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.71934617 0.09203502 0.83250993 0.6047849  0.17560044]\n",
            "  - Predicted : [0.83250993 0.83250993 0.71934617 0.71934617 0.71934617]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.38021177 0.08302759 0.7770105  0.744879   0.490231  ]\n",
            "  - Predicted : [0.490231   0.38021177 0.490231   0.490231   0.490231  ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.45201638 0.46342462 0.03746678 0.36824498 0.12850398]\n",
            "  - Predicted : [0.36824498 0.12850398 0.12850398 0.12850398 0.12850398]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.18479237 0.9621167  0.2617852  0.48362496 0.88779247]\n",
            "  - Predicted : [0.18479237 0.18479237 0.9621167  0.9621167  0.9621167 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.4134914  0.52861816 0.16878773 0.2850794  0.5061142 ]\n",
            "  - Predicted : [0.5061142 0.4134914 0.5061142 0.5061142 0.5061142]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.36490148 0.0382557  0.40082905 0.81510574 0.11605944]\n",
            "  - Predicted : [0.36490148 0.36490148 0.11605944 0.11605944 0.11605944]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.01873139 0.11870275 0.6868702  0.79464465 0.04872655]\n",
            "  - Predicted : [0.01873139 0.04872655 0.04872655 0.6868702  0.6868702 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.8875509  0.62732536 0.5181314  0.2535919  0.37170032]\n",
            "  - Predicted : [0.37170032 0.2535919  0.8875509  0.8875509  0.8875509 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.94697326 0.9115464  0.62546456 0.57891124 0.21054466]\n",
            "  - Predicted : [0.21054466 0.21054466 0.94697326 0.94697326 0.94697326]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.95327854 0.7553917  0.3822597  0.81583154 0.21187466]\n",
            "  - Predicted : [0.21187466 0.21187466 0.95327854 0.95327854 0.95327854]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.21322866 0.7909612  0.559308   0.5558353  0.5736708 ]\n",
            "  - Predicted : [0.21322866 0.21322866 0.7909612  0.5558353  0.7909612 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.12580682 0.34955907 0.57307965 0.24758843 0.50400496]\n",
            "  - Predicted : [0.12580682 0.34955907 0.57307965 0.50400496 0.50400496]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.55703527 0.9428139  0.2457758  0.43935728 0.98151124]\n",
            "  - Predicted : [0.2457758  0.2457758  0.55703527 0.9428139  0.55703527]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.18678987 0.78001946 0.17715496 0.8500466  0.48797393]\n",
            "  - Predicted : [0.18678987 0.18678987 0.78001946 0.8500466  0.8500466 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.9721615  0.17007497 0.68792635 0.69527924 0.7188754 ]\n",
            "  - Predicted : [0.7188754 0.7188754 0.9721615 0.9721615 0.9721615]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.10096876 0.288561   0.33801684 0.3242876  0.6750207 ]\n",
            "  - Predicted : [0.10096876 0.288561   0.6750207  0.6750207  0.6750207 ]\n",
            "\n",
            "\n",
            "\n",
            "loss: 2.0038867\n",
            "\n",
            "*********************************************************************************************************************************************\n",
            "\n",
            "Seq: 6 Size: 50\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------\n",
            "====== Actual : [0.05482967 0.73007864 0.5265844  0.17299716 0.22611868 0.09758031]\n",
            "  - Predicted : [0.05482967 0.17299716 0.73007864 0.73007864 0.73007864 0.73007864]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.45905885 0.5949214  0.5809721  0.9623679  0.29596603 0.76207983]\n",
            "  - Predicted : [0.9623679  0.76207983 0.76207983 0.76207983 0.76207983 0.76207983]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.72307754 0.06132698 0.9300051  0.9313039  0.39633518 0.41767785]\n",
            "  - Predicted : [0.9300051  0.41767785 0.72307754 0.72307754 0.9300051  0.72307754]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.81959695 0.49503064 0.7992007  0.03612517 0.2502706  0.09106498]\n",
            "  - Predicted : [0.03612517 0.49503064 0.03612517 0.49503064 0.03612517 0.49503064]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.45419806 0.8541595  0.56978774 0.5203335  0.3661069  0.06360988]\n",
            "  - Predicted : [0.56978774 0.45419806 0.06360988 0.5203335  0.06360988 0.5203335 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.7664097  0.5707661  0.9309655  0.43196523 0.40149963 0.974347  ]\n",
            "  - Predicted : [0.5707661 0.974347  0.7664097 0.7664097 0.7664097 0.7664097]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.1411575  0.25236154 0.48816422 0.5235443  0.5487166  0.21210992]\n",
            "  - Predicted : [0.1411575  0.48816422 0.5487166  0.5487166  0.5487166  0.5487166 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.92684805 0.7035021  0.25843984 0.294193   0.88035846 0.38035542]\n",
            "  - Predicted : [0.88035846 0.88035846 0.92684805 0.92684805 0.92684805 0.92684805]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.55636334 0.12042678 0.2517328  0.41657668 0.6561374  0.28022066]\n",
            "  - Predicted : [0.2517328  0.28022066 0.28022066 0.28022066 0.28022066 0.28022066]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.9507615  0.22021715 0.7789069  0.3645988  0.8334009  0.9231057 ]\n",
            "  - Predicted : [0.8334009 0.8334009 0.9507615 0.9507615 0.9507615 0.9507615]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.18701556 0.49147704 0.15436587 0.7058252  0.8322381  0.38946792]\n",
            "  - Predicted : [0.18701556 0.49147704 0.7058252  0.7058252  0.7058252  0.7058252 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.3967509  0.20383978 0.30653465 0.32389307 0.15557428 0.30995223]\n",
            "  - Predicted : [0.30653465 0.3967509  0.30995223 0.30995223 0.30995223 0.30995223]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.9072569  0.32538584 0.2744372  0.38464227 0.960273   0.7645791 ]\n",
            "  - Predicted : [0.7645791 0.7645791 0.9072569 0.9072569 0.9072569 0.9072569]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.20173831 0.7525516  0.7662348  0.9501371  0.8910951  0.09519498]\n",
            "  - Predicted : [0.20173831 0.20173831 0.7525516  0.9501371  0.9501371  0.9501371 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.45457655 0.7029936  0.9733688  0.08515472 0.36823276 0.4922238 ]\n",
            "  - Predicted : [0.9733688 0.4922238 0.4922238 0.4922238 0.4922238 0.4922238]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.4132442  0.45577845 0.36910215 0.9706226  0.80324477 0.7366599 ]\n",
            "  - Predicted : [0.9706226  0.7366599  0.80324477 0.80324477 0.80324477 0.80324477]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.41070136 0.8815236  0.09333929 0.14341852 0.9540579  0.5669883 ]\n",
            "  - Predicted : [0.8815236 0.9540579 0.9540579 0.9540579 0.9540579 0.9540579]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.15945777 0.94914573 0.97484326 0.8814931  0.23855786 0.278494  ]\n",
            "  - Predicted : [0.15945777 0.15945777 0.94914573 0.8814931  0.8814931  0.8814931 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.40697286 0.57932174 0.9921814  0.95613354 0.92113906 0.0892763 ]\n",
            "  - Predicted : [0.9921814  0.92113906 0.92113906 0.92113906 0.92113906 0.92113906]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.7571663  0.87684584 0.33327952 0.21957403 0.7484415  0.09083775]\n",
            "  - Predicted : [0.87684584 0.09083775 0.7571663  0.7571663  0.7571663  0.7571663 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.9408582  0.15607764 0.45753786 0.98279786 0.9882202  0.7759903 ]\n",
            "  - Predicted : [0.9882202 0.9882202 0.9408582 0.9408582 0.9408582 0.9408582]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.83918846 0.9671707  0.9274295  0.62210864 0.734617   0.5937766 ]\n",
            "  - Predicted : [0.62210864 0.5937766  0.83918846 0.83918846 0.83918846 0.83918846]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.5064953  0.88082904 0.7380251  0.8598162  0.09591097 0.57648516]\n",
            "  - Predicted : [0.8598162  0.5064953  0.57648516 0.57648516 0.57648516 0.8598162 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.32951683 0.513394   0.61296546 0.8457585  0.03187773 0.16398337]\n",
            "  - Predicted : [0.513394   0.8457585  0.16398337 0.16398337 0.16398337 0.16398337]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.9214457  0.96727073 0.05542268 0.33178756 0.00972997 0.757448  ]\n",
            "  - Predicted : [0.00972997 0.05542268 0.05542268 0.05542268 0.00972997 0.00972997]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.6819402  0.5648051  0.6916612  0.5377912  0.23884118 0.75433373]\n",
            "  - Predicted : [0.6916612 0.5648051 0.6819402 0.5648051 0.5648051 0.5648051]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.78327775 0.8542019  0.9540767  0.7475416  0.05454979 0.02083857]\n",
            "  - Predicted : [0.9540767  0.9540767  0.78327775 0.78327775 0.78327775 0.78327775]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.73987067 0.05605096 0.3159446  0.13615988 0.9688999  0.31639415]\n",
            "  - Predicted : [0.05605096 0.3159446  0.3159446  0.13615988 0.3159446  0.3159446 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.05514691 0.94960755 0.6087444  0.03610907 0.833361   0.1525287 ]\n",
            "  - Predicted : [0.05514691 0.03610907 0.03610907 0.833361   0.833361   0.833361  ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.8024363  0.60275173 0.17711522 0.75259805 0.45450497 0.6381009 ]\n",
            "  - Predicted : [0.75259805 0.17711522 0.8024363  0.8024363  0.8024363  0.8024363 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.86951417 0.2602981  0.36597133 0.9972718  0.50811446 0.5585027 ]\n",
            "  - Predicted : [0.9972718  0.5585027  0.86951417 0.86951417 0.86951417 0.86951417]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.28543854 0.41602725 0.50155175 0.25844473 0.23814552 0.6004668 ]\n",
            "  - Predicted : [0.28543854 0.28543854 0.50155175 0.6004668  0.6004668  0.6004668 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.18365145 0.55345774 0.706214   0.19825763 0.74587804 0.35968438]\n",
            "  - Predicted : [0.18365145 0.55345774 0.74587804 0.74587804 0.74587804 0.74587804]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.99250454 0.9790768  0.79859465 0.34272078 0.93721014 0.998779  ]\n",
            "  - Predicted : [0.998779   0.998779   0.99250454 0.99250454 0.99250454 0.99250454]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.46227857 0.6145894  0.005987   0.04353321 0.50059783 0.60931385]\n",
            "  - Predicted : [0.04353321 0.46227857 0.60931385 0.60931385 0.60931385 0.60931385]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.312393   0.09912982 0.78227216 0.41876003 0.6488484  0.6502012 ]\n",
            "  - Predicted : [0.09912982 0.312393   0.78227216 0.6502012  0.6502012  0.6502012 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.5468387  0.17848957 0.61608136 0.322084   0.81912524 0.19319685]\n",
            "  - Predicted : [0.61608136 0.19319685 0.19319685 0.19319685 0.19319685 0.19319685]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.29114842 0.44030598 0.7400131  0.7207506  0.33710995 0.510752  ]\n",
            "  - Predicted : [0.29114842 0.29114842 0.7400131  0.510752   0.510752   0.510752  ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.2342346  0.7703653  0.19670989 0.8193469  0.9368641  0.9916161 ]\n",
            "  - Predicted : [0.2342346 0.7703653 0.9916161 0.9916161 0.9916161 0.9916161]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.85696214 0.22169898 0.41651362 0.08883685 0.16455136 0.04969708]\n",
            "  - Predicted : [0.08883685 0.22169898 0.22169898 0.22169898 0.22169898 0.22169898]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.6410879  0.53318715 0.9170128  0.4630077  0.6423067  0.40159747]\n",
            "  - Predicted : [0.9170128  0.40159747 0.6410879  0.53318715 0.9170128  0.53318715]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.82945704 0.9263757  0.43173173 0.08270132 0.16353583 0.72054434]\n",
            "  - Predicted : [0.08270132 0.9263757  0.82945704 0.82945704 0.82945704 0.82945704]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.32526746 0.78538495 0.74975955 0.69430166 0.8142169  0.75655586]\n",
            "  - Predicted : [0.78538495 0.75655586 0.75655586 0.75655586 0.75655586 0.75655586]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.6325879  0.00422721 0.5156772  0.5952529  0.9606459  0.65048206]\n",
            "  - Predicted : [0.5156772  0.65048206 0.6325879  0.5952529  0.5952529  0.5952529 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.5754737  0.54119384 0.10329299 0.42761987 0.1343557  0.05269775]\n",
            "  - Predicted : [0.10329299 0.54119384 0.1343557  0.1343557  0.1343557  0.1343557 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.3294692  0.6454422  0.8667973  0.81036586 0.29468986 0.04599662]\n",
            "  - Predicted : [0.3294692  0.3294692  0.8667973  0.04599662 0.8667973  0.04599662]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.40267816 0.31477928 0.37126455 0.55909896 0.03041352 0.37080574]\n",
            "  - Predicted : [0.37126455 0.40267816 0.37080574 0.37080574 0.37080574 0.37080574]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.5586333  0.43097088 0.66722894 0.18613179 0.15382811 0.3078744 ]\n",
            "  - Predicted : [0.66722894 0.3078744  0.3078744  0.3078744  0.3078744  0.3078744 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.10172924 0.23626187 0.08690446 0.40197775 0.71145606 0.2865381 ]\n",
            "  - Predicted : [0.10172924 0.40197775 0.71145606 0.71145606 0.71145606 0.71145606]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.00373091 0.55706745 0.69194156 0.39131618 0.2969999  0.4906378 ]\n",
            "  - Predicted : [0.00373091 0.4906378  0.4906378  0.55706745 0.55706745 0.55706745]\n",
            "\n",
            "\n",
            "\n",
            "loss: 2.198706\n",
            "\n",
            "\n",
            "Seq: 7 Size: 50\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------\n",
            "====== Actual : [0.10123967 0.6439262  0.73329717 0.7046307  0.32866693 0.8427107\n",
            " 0.94684875]\n",
            "  - Predicted : [0.7046307  0.94684875 0.94684875 0.94684875 0.94684875 0.94684875\n",
            " 0.94684875]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.29707423 0.26271918 0.70410573 0.70828193 0.5104174  0.92332\n",
            " 0.14631502]\n",
            "  - Predicted : [0.26271918 0.70410573 0.14631502 0.26271918 0.26271918 0.70410573\n",
            " 0.14631502]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.4773671  0.03520687 0.05265594 0.05368453 0.49178818 0.5889646\n",
            " 0.0034875 ]\n",
            "  - Predicted : [0.0034875 0.4773671 0.0034875 0.4773671 0.0034875 0.4773671 0.0034875]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.6325464  0.48970076 0.22380188 0.01510012 0.1561032  0.60033226\n",
            " 0.6588402 ]\n",
            "  - Predicted : [0.22380188 0.48970076 0.22380188 0.22380188 0.22380188 0.22380188\n",
            " 0.22380188]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.6470612  0.15316232 0.9112143  0.41095206 0.7680074  0.16648094\n",
            " 0.47056872]\n",
            "  - Predicted : [0.9112143 0.6470612 0.9112143 0.9112143 0.9112143 0.9112143 0.9112143]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.52152115 0.7703552  0.6215189  0.39930248 0.28251466 0.9729568\n",
            " 0.28452998]\n",
            "  - Predicted : [0.39930248 0.28452998 0.7703552  0.39930248 0.39930248 0.39930248\n",
            " 0.39930248]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.12947392 0.30041668 0.3269364  0.1278595  0.7081451  0.619165\n",
            " 0.3166155 ]\n",
            "  - Predicted : [0.1278595 0.7081451 0.3166155 0.3166155 0.7081451 0.3166155 0.7081451]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.9930001  0.65501106 0.7031854  0.55718267 0.55157477 0.02002227\n",
            " 0.77090627]\n",
            "  - Predicted : [0.77090627 0.77090627 0.77090627 0.77090627 0.77090627 0.77090627\n",
            " 0.77090627]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.91074073 0.12226398 0.79563046 0.534307   0.28530917 0.9208841\n",
            " 0.0173709 ]\n",
            "  - Predicted : [0.28530917 0.91074073 0.28530917 0.28530917 0.12226398 0.12226398\n",
            " 0.12226398]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.27405855 0.88624984 0.4810145  0.5989218  0.749768   0.14797361\n",
            " 0.2151751 ]\n",
            "  - Predicted : [0.27405855 0.88624984 0.88624984 0.88624984 0.88624984 0.88624984\n",
            " 0.88624984]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.99862885 0.2374527  0.5392025  0.29870728 0.8514197  0.9617558\n",
            " 0.14129241]\n",
            "  - Predicted : [0.14129241 0.14129241 0.2374527  0.2374527  0.2374527  0.2374527\n",
            " 0.2374527 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.6005735  0.81157655 0.82302785 0.4404477  0.22537634 0.38713992\n",
            " 0.7511527 ]\n",
            "  - Predicted : [0.82302785 0.81157655 0.82302785 0.82302785 0.82302785 0.82302785\n",
            " 0.82302785]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.9937779  0.5542892  0.1951244  0.04193477 0.9436898  0.4830332\n",
            " 0.71659267]\n",
            "  - Predicted : [0.71659267 0.71659267 0.71659267 0.71659267 0.71659267 0.71659267\n",
            " 0.71659267]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.66018105 0.8908713  0.26609057 0.4417201  0.9136208  0.5855762\n",
            " 0.07136164]\n",
            "  - Predicted : [0.26609057 0.8908713  0.8908713  0.26609057 0.26609057 0.26609057\n",
            " 0.26609057]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.19448417 0.23721501 0.9937855  0.22413899 0.8696841  0.07809565\n",
            " 0.18172069]\n",
            "  - Predicted : [0.23721501 0.9937855  0.9937855  0.9937855  0.9937855  0.9937855\n",
            " 0.9937855 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.87205523 0.89893645 0.17619625 0.22985218 0.53056735 0.05268295\n",
            " 0.9452842 ]\n",
            "  - Predicted : [0.22985218 0.87205523 0.22985218 0.89893645 0.22985218 0.22985218\n",
            " 0.89893645]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.36207673 0.48928797 0.10504836 0.03254464 0.46781692 0.12166737\n",
            " 0.6303187 ]\n",
            "  - Predicted : [0.12166737 0.12166737 0.36207673 0.48928797 0.12166737 0.36207673\n",
            " 0.48928797]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.7944813  0.03167113 0.6122225  0.81562674 0.43942797 0.95970464\n",
            " 0.11119491]\n",
            "  - Predicted : [0.81562674 0.7944813  0.6122225  0.81562674 0.81562674 0.81562674\n",
            " 0.81562674]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.32298446 0.23007503 0.99619114 0.29417634 0.38792676 0.8476165\n",
            " 0.9299635 ]\n",
            "  - Predicted : [0.99619114 0.9299635  0.99619114 0.99619114 0.99619114 0.99619114\n",
            " 0.99619114]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.93774724 0.55816805 0.66330224 0.34917173 0.6071587  0.30274805\n",
            " 0.74602836]\n",
            "  - Predicted : [0.30274805 0.93774724 0.6071587  0.30274805 0.6071587  0.30274805\n",
            " 0.6071587 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.30721012 0.8794107  0.14348389 0.5718051  0.5206755  0.26371747\n",
            " 0.02800211]\n",
            "  - Predicted : [0.8794107  0.02800211 0.30721012 0.8794107  0.02800211 0.8794107\n",
            " 0.02800211]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.14853369 0.9679512  0.9413045  0.11930072 0.3748602  0.46512663\n",
            " 0.47807193]\n",
            "  - Predicted : [0.14853369 0.9679512  0.9679512  0.9679512  0.9679512  0.9679512\n",
            " 0.9679512 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.2988198  0.91295284 0.9084906  0.01892842 0.65000135 0.07436241\n",
            " 0.59749764]\n",
            "  - Predicted : [0.91295284 0.9084906  0.9084906  0.9084906  0.9084906  0.9084906\n",
            " 0.9084906 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.8668929  0.64953095 0.46892762 0.95789576 0.7465986  0.24930938\n",
            " 0.3869369 ]\n",
            "  - Predicted : [0.24930938 0.8668929  0.24930938 0.64953095 0.24930938 0.46892762\n",
            " 0.46892762]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.75987536 0.01931425 0.0639633  0.85942316 0.04294599 0.6785138\n",
            " 0.31890595]\n",
            "  - Predicted : [0.01931425 0.75987536 0.01931425 0.01931425 0.01931425 0.01931425\n",
            " 0.01931425]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.82589173 0.84734607 0.9533391  0.09554955 0.422847   0.5739586\n",
            " 0.9160569 ]\n",
            "  - Predicted : [0.09554955 0.84734607 0.09554955 0.84734607 0.09554955 0.84734607\n",
            " 0.09554955]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.26651415 0.07162749 0.20176461 0.49557832 0.681051   0.690674\n",
            " 0.0746633 ]\n",
            "  - Predicted : [0.07162749 0.07162749 0.07162749 0.07162749 0.07162749 0.07162749\n",
            " 0.07162749]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.76141024 0.6602394  0.40754318 0.5710863  0.7677404  0.26209274\n",
            " 0.9400335 ]\n",
            "  - Predicted : [0.40754318 0.76141024 0.6602394  0.6602394  0.6602394  0.6602394\n",
            " 0.6602394 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.1377676  0.9022228  0.74085796 0.66051865 0.082908   0.9190046\n",
            " 0.29533035]\n",
            "  - Predicted : [0.1377676  0.66051865 0.66051865 0.66051865 0.66051865 0.66051865\n",
            " 0.66051865]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.7456122  0.8848014  0.2442835  0.9146008  0.61194164 0.6590318\n",
            " 0.9145129 ]\n",
            "  - Predicted : [0.8848014 0.7456122 0.8848014 0.8848014 0.8848014 0.8848014 0.8848014]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.52673495 0.44064757 0.63323176 0.5540235  0.06147571 0.18049204\n",
            " 0.01356648]\n",
            "  - Predicted : [0.63323176 0.01356648 0.44064757 0.63323176 0.63323176 0.63323176\n",
            " 0.63323176]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.10816284 0.72984964 0.00471116 0.3044055  0.44932142 0.93781227\n",
            " 0.32700703]\n",
            "  - Predicted : [0.10816284 0.93781227 0.93781227 0.93781227 0.93781227 0.93781227\n",
            " 0.93781227]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.78313076 0.40876558 0.09849138 0.09884375 0.4324338  0.05788313\n",
            " 0.5716192 ]\n",
            "  - Predicted : [0.09849138 0.78313076 0.09849138 0.40876558 0.40876558 0.09849138\n",
            " 0.40876558]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.49364972 0.7025352  0.18562153 0.59292924 0.17452247 0.7222337\n",
            " 0.30715865]\n",
            "  - Predicted : [0.59292924 0.30715865 0.30715865 0.30715865 0.30715865 0.30715865\n",
            " 0.30715865]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.6144162  0.88267726 0.48823413 0.19229211 0.8861229  0.35857955\n",
            " 0.73025286]\n",
            "  - Predicted : [0.48823413 0.88267726 0.88267726 0.48823413 0.48823413 0.48823413\n",
            " 0.48823413]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.3200957  0.29821545 0.6420283  0.15631144 0.8669739  0.387624\n",
            " 0.01927744]\n",
            "  - Predicted : [0.29821545 0.01927744 0.3200957  0.29821545 0.29821545 0.6420283\n",
            " 0.01927744]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.30543646 0.78496635 0.85935885 0.5678803  0.2941093  0.5278541\n",
            " 0.8363753 ]\n",
            "  - Predicted : [0.78496635 0.8363753  0.85935885 0.85935885 0.85935885 0.85935885\n",
            " 0.85935885]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.31603783 0.38543698 0.53969413 0.8871382  0.5821489  0.20761515\n",
            " 0.08910404]\n",
            "  - Predicted : [0.38543698 0.08910404 0.31603783 0.38543698 0.38543698 0.53969413\n",
            " 0.08910404]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.09501395 0.95024955 0.8224125  0.7658547  0.4963646  0.6725396\n",
            " 0.1273303 ]\n",
            "  - Predicted : [0.09501395 0.7658547  0.7658547  0.7658547  0.7658547  0.7658547\n",
            " 0.7658547 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.62089574 0.8107807  0.06213874 0.29615042 0.11027867 0.26022702\n",
            " 0.7725239 ]\n",
            "  - Predicted : [0.06213874 0.62089574 0.8107807  0.06213874 0.06213874 0.06213874\n",
            " 0.06213874]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.33204916 0.68968385 0.7733025  0.8166387  0.8733754  0.5976358\n",
            " 0.28063983]\n",
            "  - Predicted : [0.68968385 0.5976358  0.5976358  0.5976358  0.5976358  0.5976358\n",
            " 0.5976358 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.15055853 0.50370866 0.10355723 0.910724   0.44248024 0.8729842\n",
            " 0.70927036]\n",
            "  - Predicted : [0.10355723 0.910724   0.910724   0.910724   0.910724   0.910724\n",
            " 0.910724  ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.85721755 0.8839581  0.0532935  0.7252579  0.2265477  0.9892969\n",
            " 0.778403  ]\n",
            "  - Predicted : [0.2265477  0.85721755 0.2265477  0.8839581  0.2265477  0.8839581\n",
            " 0.2265477 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.003765   0.9274163  0.29230592 0.4166536  0.61228555 0.9163098\n",
            " 0.9273266 ]\n",
            "  - Predicted : [0.9273266 0.9273266 0.9273266 0.9273266 0.9273266 0.9273266 0.9273266]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.56347173 0.3167245  0.27918994 0.3643971  0.18051368 0.669833\n",
            " 0.52780205]\n",
            "  - Predicted : [0.27918994 0.669833   0.27918994 0.27918994 0.27918994 0.27918994\n",
            " 0.27918994]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.7734647  0.09411132 0.39990583 0.23986287 0.53518623 0.468244\n",
            " 0.44956544]\n",
            "  - Predicted : [0.39990583 0.7734647  0.39990583 0.09411132 0.09411132 0.09411132\n",
            " 0.09411132]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.31565362 0.72684556 0.4815677  0.20224378 0.5474475  0.5966722\n",
            " 0.02137968]\n",
            "  - Predicted : [0.72684556 0.02137968 0.31565362 0.72684556 0.02137968 0.72684556\n",
            " 0.02137968]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.20377865 0.24240391 0.24807516 0.23884587 0.27164117 0.26272723\n",
            " 0.88406885]\n",
            "  - Predicted : [0.24240391 0.88406885 0.88406885 0.88406885 0.88406885 0.88406885\n",
            " 0.88406885]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.31964788 0.3497627  0.26617727 0.96757436 0.5354908  0.6105461\n",
            " 0.7354873 ]\n",
            "  - Predicted : [0.3497627 0.7354873 0.7354873 0.7354873 0.7354873 0.7354873 0.7354873]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.33371407 0.96878046 0.15232617 0.4578146  0.14543927 0.79037577\n",
            " 0.10731769]\n",
            "  - Predicted : [0.96878046 0.10731769 0.33371407 0.96878046 0.10731769 0.96878046\n",
            " 0.10731769]\n",
            "\n",
            "\n",
            "\n",
            "loss: 2.422537\n",
            "\n",
            "\n",
            "Seq: 8 Size: 50\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------\n",
            "====== Actual : [0.5538996  0.10480627 0.4526619  0.28030798 0.90329677 0.0530958\n",
            " 0.6499376  0.6952512 ]\n",
            "  - Predicted : [0.4526619 0.6952512 0.0530958 0.0530958 0.0530958 0.4526619 0.0530958\n",
            " 0.0530958]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.8889821  0.8777295  0.97705626 0.25390935 0.27482536 0.39729273\n",
            " 0.537577   0.36714193]\n",
            "  - Predicted : [0.36714193 0.36714193 0.8889821  0.8889821  0.8889821  0.8889821\n",
            " 0.8889821  0.8889821 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.7402964  0.00854505 0.01765432 0.71605676 0.88312125 0.77654743\n",
            " 0.11709161 0.934974  ]\n",
            "  - Predicted : [0.00854505 0.01765432 0.00854505 0.00854505 0.00854505 0.00854505\n",
            " 0.00854505 0.00854505]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.52191263 0.74229515 0.2010462  0.54879564 0.3300608  0.9747608\n",
            " 0.47419614 0.75557697]\n",
            "  - Predicted : [0.2010462  0.74229515 0.47419614 0.47419614 0.47419614 0.47419614\n",
            " 0.47419614 0.47419614]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.6032319  0.09429875 0.54292774 0.54021585 0.7157093  0.32190803\n",
            " 0.8606521  0.6226035 ]\n",
            "  - Predicted : [0.54292774 0.7157093  0.6226035  0.7157093  0.7157093  0.7157093\n",
            " 0.7157093  0.7157093 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.03934132 0.7068358  0.9069669  0.6831471  0.3799973  0.59064883\n",
            " 0.17139827 0.6012555 ]\n",
            "  - Predicted : [0.03934132 0.17139827 0.9069669  0.9069669  0.9069669  0.9069669\n",
            " 0.9069669  0.9069669 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.5009927  0.02615769 0.32188988 0.19124725 0.39065194 0.24183244\n",
            " 0.8342487  0.6976835 ]\n",
            "  - Predicted : [0.19124725 0.02615769 0.6976835  0.6976835  0.24183244 0.24183244\n",
            " 0.24183244 0.24183244]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.74011475 0.36086732 0.00344637 0.21915369 0.7552982  0.6028368\n",
            " 0.53857815 0.28051993]\n",
            "  - Predicted : [0.36086732 0.36086732 0.74011475 0.74011475 0.6028368  0.36086732\n",
            " 0.36086732 0.36086732]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.07574233 0.78486645 0.03865557 0.05913647 0.29493523 0.5729337\n",
            " 0.99222654 0.09064157]\n",
            "  - Predicted : [0.07574233 0.09064157 0.03865557 0.03865557 0.03865557 0.03865557\n",
            " 0.03865557 0.03865557]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.4731708  0.6017533  0.8231052  0.68961394 0.8077416  0.522469\n",
            " 0.4339708  0.61872834]\n",
            "  - Predicted : [0.68961394 0.4731708  0.61872834 0.4339708  0.4339708  0.4339708\n",
            " 0.4339708  0.4339708 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.9008708  0.5508472  0.60559314 0.33797616 0.59612143 0.6277641\n",
            " 0.7534255  0.5721767 ]\n",
            "  - Predicted : [0.5721767 0.5721767 0.9008708 0.9008708 0.9008708 0.9008708 0.9008708\n",
            " 0.9008708]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.1975503  0.5819261  0.2978714  0.08732449 0.82543314 0.06607211\n",
            " 0.63170326 0.98849463]\n",
            "  - Predicted : [0.1975503  0.1975503  0.82543314 0.63170326 0.82543314 0.82543314\n",
            " 0.82543314 0.82543314]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [8.7619171e-02 2.2013184e-01 7.6080424e-01 9.6894130e-02 8.3272505e-01\n",
            " 2.7012237e-04 8.8994735e-01 6.6823155e-02]\n",
            "  - Predicted : [0.08761917 0.22013184 0.76080424 0.83272505 0.88994735 0.88994735\n",
            " 0.88994735 0.88994735]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.92197984 0.86455125 0.5395631  0.7779486  0.07487684 0.13514785\n",
            " 0.36928734 0.5374586 ]\n",
            "  - Predicted : [0.5374586  0.5374586  0.92197984 0.92197984 0.92197984 0.92197984\n",
            " 0.92197984 0.92197984]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.86821425 0.54268044 0.6652052  0.67988443 0.8775681  0.77675474\n",
            " 0.9770303  0.02001264]\n",
            "  - Predicted : [0.8775681  0.02001264 0.86821425 0.86821425 0.86821425 0.86821425\n",
            " 0.86821425 0.86821425]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.20782867 0.93044573 0.79222023 0.26736274 0.9742467  0.86988103\n",
            " 0.06465723 0.8113099 ]\n",
            "  - Predicted : [0.20782867 0.20782867 0.93044573 0.9742467  0.9742467  0.9742467\n",
            " 0.9742467  0.9742467 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.7844876  0.22115305 0.6692465  0.97022593 0.6758688  0.81376517\n",
            " 0.09938652 0.7274588 ]\n",
            "  - Predicted : [0.97022593 0.6692465  0.6692465  0.7844876  0.7844876  0.6692465\n",
            " 0.6692465  0.6692465 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.20475471 0.07185417 0.5520774  0.7506111  0.5467449  0.9315969\n",
            " 0.6956664  0.11757483]\n",
            "  - Predicted : [0.07185417 0.20475471 0.9315969  0.9315969  0.9315969  0.9315969\n",
            " 0.9315969  0.9315969 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.9345182  0.15288799 0.7582554  0.14854369 0.9985803  0.3321875\n",
            " 0.49592933 0.4668375 ]\n",
            "  - Predicted : [0.4668375 0.4668375 0.9345182 0.9345182 0.9345182 0.9345182 0.9345182\n",
            " 0.9345182]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.1018972  0.494015   0.14950599 0.8019808  0.9583134  0.80805844\n",
            " 0.431064   0.0023714 ]\n",
            "  - Predicted : [0.1018972  0.14950599 0.8019808  0.9583134  0.9583134  0.9583134\n",
            " 0.9583134  0.9583134 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.03664346 0.49503514 0.6794873  0.81951404 0.59953153 0.97831315\n",
            " 0.49377802 0.6000288 ]\n",
            "  - Predicted : [0.03664346 0.49377802 0.97831315 0.97831315 0.97831315 0.97831315\n",
            " 0.97831315 0.97831315]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.23010233 0.3396605  0.68313175 0.60164136 0.36964887 0.11198195\n",
            " 0.34261522 0.04415559]\n",
            "  - Predicted : [0.3396605  0.23010233 0.04415559 0.04415559 0.04415559 0.04415559\n",
            " 0.04415559 0.04415559]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.5807672  0.32301548 0.3798485  0.5750882  0.5812878  0.5883433\n",
            " 0.49159122 0.48812243]\n",
            "  - Predicted : [0.3798485 0.5883433 0.5807672 0.5812878 0.5812878 0.5812878 0.5812878\n",
            " 0.5812878]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.82121944 0.46755445 0.5360302  0.9882299  0.18105005 0.726421\n",
            " 0.47318718 0.8305417 ]\n",
            "  - Predicted : [0.9882299  0.8305417  0.8305417  0.82121944 0.82121944 0.82121944\n",
            " 0.82121944 0.82121944]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.40403256 0.30298942 0.20778619 0.87223715 0.7183285  0.07690045\n",
            " 0.71349025 0.03501563]\n",
            "  - Predicted : [0.87223715 0.03501563 0.03501563 0.03501563 0.03501563 0.7183285\n",
            " 0.03501563 0.03501563]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.18162641 0.5927977  0.46351033 0.8404836  0.60789037 0.9649746\n",
            " 0.85518354 0.3402153 ]\n",
            "  - Predicted : [0.18162641 0.18162641 0.5927977  0.9649746  0.9649746  0.9649746\n",
            " 0.9649746  0.9649746 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.83415097 0.8699353  0.969725   0.01256293 0.8747443  0.06989531\n",
            " 0.52811587 0.41466355]\n",
            "  - Predicted : [0.01256293 0.8699353  0.01256293 0.8699353  0.83415097 0.01256293\n",
            " 0.01256293 0.01256293]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.91988164 0.40515184 0.5960427  0.6918787  0.01902976 0.59093124\n",
            " 0.51799184 0.5940086 ]\n",
            "  - Predicted : [0.5940086  0.5940086  0.91988164 0.91988164 0.91988164 0.91988164\n",
            " 0.91988164 0.91988164]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.07574406 0.05555837 0.17754434 0.8695007  0.35647106 0.43403256\n",
            " 0.39016628 0.71437013]\n",
            "  - Predicted : [0.07574406 0.8695007  0.71437013 0.71437013 0.71437013 0.71437013\n",
            " 0.71437013 0.71437013]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.25947556 0.06839335 0.3781749  0.72783554 0.914968   0.05082157\n",
            " 0.8104961  0.06618015]\n",
            "  - Predicted : [0.06839335 0.25947556 0.8104961  0.8104961  0.8104961  0.8104961\n",
            " 0.8104961  0.8104961 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.3306606  0.02230153 0.9115417  0.706789   0.36913523 0.37745658\n",
            " 0.63984287 0.08964831]\n",
            "  - Predicted : [0.9115417  0.08964831 0.08964831 0.08964831 0.08964831 0.37745658\n",
            " 0.08964831 0.08964831]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.14504863 0.84722424 0.20231308 0.7266664  0.2258029  0.08814631\n",
            " 0.90003234 0.9016728 ]\n",
            "  - Predicted : [0.14504863 0.20231308 0.20231308 0.20231308 0.84722424 0.84722424\n",
            " 0.84722424 0.84722424]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.6053119  0.46203384 0.55275995 0.40812743 0.7571746  0.7545607\n",
            " 0.8189796  0.5229261 ]\n",
            "  - Predicted : [0.55275995 0.5229261  0.5229261  0.7571746  0.7571746  0.7571746\n",
            " 0.7571746  0.7571746 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.8013419  0.1557186  0.03013473 0.64805305 0.10547601 0.5506699\n",
            " 0.72112495 0.40708542]\n",
            "  - Predicted : [0.64805305 0.03013473 0.8013419  0.8013419  0.8013419  0.40708542\n",
            " 0.10547601 0.10547601]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.04387271 0.8871314  0.04324504 0.9047525  0.05263059 0.7351595\n",
            " 0.92484677 0.90698034]\n",
            "  - Predicted : [0.04387271 0.05263059 0.8871314  0.9047525  0.9047525  0.9047525\n",
            " 0.9047525  0.9047525 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.89338493 0.88307863 0.5104097  0.55769086 0.6197175  0.8959484\n",
            " 0.8381604  0.7829786 ]\n",
            "  - Predicted : [0.7829786  0.7829786  0.7829786  0.89338493 0.89338493 0.89338493\n",
            " 0.89338493 0.89338493]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.6757242  0.6183837  0.9224669  0.1926442  0.192725   0.98246956\n",
            " 0.55315906 0.48337412]\n",
            "  - Predicted : [0.9224669  0.48337412 0.48337412 0.192725   0.9224669  0.192725\n",
            " 0.9224669  0.192725  ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.85059536 0.8497679  0.17659801 0.1735723  0.7952648  0.78563243\n",
            " 0.22518669 0.8415101 ]\n",
            "  - Predicted : [0.7952648  0.8415101  0.8415101  0.85059536 0.85059536 0.85059536\n",
            " 0.85059536 0.85059536]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.48005113 0.46998912 0.9856936  0.5192146  0.13704538 0.2801558\n",
            " 0.33368212 0.95846695]\n",
            "  - Predicted : [0.5192146  0.48005113 0.95846695 0.33368212 0.33368212 0.33368212\n",
            " 0.33368212 0.33368212]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.26403737 0.43040293 0.7496356  0.2740963  0.70164204 0.2075176\n",
            " 0.24251747 0.98633194]\n",
            "  - Predicted : [0.7496356  0.98633194 0.98633194 0.98633194 0.98633194 0.98633194\n",
            " 0.98633194 0.98633194]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.3689444  0.72968614 0.8400631  0.3468523  0.3571695  0.77308846\n",
            " 0.60700136 0.3617519 ]\n",
            "  - Predicted : [0.8400631 0.3617519 0.3617519 0.3617519 0.3617519 0.3571695 0.3571695\n",
            " 0.3571695]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.7495661  0.863705   0.23503828 0.02435613 0.27414706 0.6744896\n",
            " 0.91525227 0.86306435]\n",
            "  - Predicted : [0.23503828 0.23503828 0.7495661  0.7495661  0.23503828 0.863705\n",
            " 0.23503828 0.23503828]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.2221706  0.88100016 0.8107317  0.7344009  0.6882269  0.8070925\n",
            " 0.8617295  0.81911147]\n",
            "  - Predicted : [0.88100016 0.88100016 0.7344009  0.81911147 0.81911147 0.81911147\n",
            " 0.81911147 0.81911147]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.12184834 0.7221548  0.84130424 0.185706   0.21379754 0.78597695\n",
            " 0.3439292  0.399701  ]\n",
            "  - Predicted : [0.12184834 0.3439292  0.185706   0.7221548  0.84130424 0.78597695\n",
            " 0.78597695 0.78597695]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.37715927 0.2128325  0.9387943  0.80586    0.2505391  0.10608717\n",
            " 0.37261018 0.41530842]\n",
            "  - Predicted : [0.9387943  0.41530842 0.41530842 0.41530842 0.41530842 0.41530842\n",
            " 0.41530842 0.41530842]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.00709213 0.88715214 0.8512839  0.8501633  0.80580324 0.7331259\n",
            " 0.6345207  0.96028924]\n",
            "  - Predicted : [0.00709213 0.6345207  0.96028924 0.96028924 0.96028924 0.96028924\n",
            " 0.96028924 0.96028924]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.71172994 0.6302451  0.7888251  0.24626632 0.96714556 0.01916198\n",
            " 0.64840496 0.0770942 ]\n",
            "  - Predicted : [0.6302451  0.0770942  0.71172994 0.01916198 0.7888251  0.01916198\n",
            " 0.7888251  0.01916198]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.8533059  0.9676401  0.40861073 0.8571647  0.33572134 0.1594037\n",
            " 0.2766494  0.30184197]\n",
            "  - Predicted : [0.33572134 0.30184197 0.8533059  0.8533059  0.8533059  0.8533059\n",
            " 0.8533059  0.8533059 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.63066804 0.79614806 0.20521654 0.08820626 0.22165184 0.29653782\n",
            " 0.27981466 0.21995047]\n",
            "  - Predicted : [0.20521654 0.20521654 0.63066804 0.79614806 0.79614806 0.79614806\n",
            " 0.79614806 0.79614806]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.4660002  0.85598284 0.1003485  0.86203    0.49700844 0.660468\n",
            " 0.8153671  0.30432692]\n",
            "  - Predicted : [0.86203    0.4660002  0.30432692 0.8153671  0.8153671  0.8153671\n",
            " 0.8153671  0.8153671 ]\n",
            "\n",
            "\n",
            "\n",
            "loss: 2.6523597\n",
            "\n",
            "\n",
            "Seq: 9 Size: 50\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------\n",
            "====== Actual : [0.9542346  0.08373626 0.52766645 0.25480336 0.4079463  0.44886413\n",
            " 0.91451174 0.44158152 0.69794786]\n",
            "  - Predicted : [0.69794786 0.69794786 0.69794786 0.69794786 0.69794786 0.69794786\n",
            " 0.69794786 0.69794786 0.69794786]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.95176315 0.4945326  0.40830994 0.97296846 0.82767636 0.9397729\n",
            " 0.39722523 0.6963244  0.24961057]\n",
            "  - Predicted : [0.24961057 0.24961057 0.24961057 0.24961057 0.24961057 0.24961057\n",
            " 0.24961057 0.24961057 0.24961057]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.865822   0.9330792  0.26786646 0.10493241 0.20073475 0.6328321\n",
            " 0.2721833  0.63861084 0.3501887 ]\n",
            "  - Predicted : [0.10493241 0.10493241 0.10493241 0.10493241 0.10493241 0.10493241\n",
            " 0.10493241 0.10493241 0.10493241]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.9168354  0.45259768 0.49762195 0.34806496 0.07303784 0.49363622\n",
            " 0.7743645  0.95301473 0.07657561]\n",
            "  - Predicted : [0.07303784 0.07657561 0.07303784 0.07303784 0.07303784 0.07303784\n",
            " 0.07303784 0.07303784 0.07303784]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.79739755 0.26706144 0.8228172  0.34201357 0.11443324 0.61201924\n",
            " 0.8939044  0.18158881 0.02180501]\n",
            "  - Predicted : [0.26706144 0.26706144 0.26706144 0.26706144 0.26706144 0.26706144\n",
            " 0.26706144 0.26706144 0.26706144]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.88384175 0.6978296  0.80869615 0.0598378  0.89045525 0.41915604\n",
            " 0.89761716 0.06492472 0.8848077 ]\n",
            "  - Predicted : [0.0598378 0.0598378 0.0598378 0.0598378 0.0598378 0.0598378 0.0598378\n",
            " 0.0598378 0.0598378]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.67337656 0.5542685  0.06178083 0.68841755 0.59777415 0.7262889\n",
            " 0.7167168  0.44373432 0.20468122]\n",
            "  - Predicted : [0.06178083 0.5542685  0.5542685  0.5542685  0.5542685  0.06178083\n",
            " 0.06178083 0.06178083 0.06178083]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.9189683  0.92558956 0.2119313  0.6306533  0.20287053 0.86122453\n",
            " 0.09821332 0.99019736 0.6108619 ]\n",
            "  - Predicted : [0.20287053 0.20287053 0.20287053 0.20287053 0.20287053 0.20287053\n",
            " 0.20287053 0.20287053 0.20287053]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.02291258 0.88190335 0.6844582  0.69732237 0.2750323  0.33679634\n",
            " 0.9144173  0.63495797 0.01695414]\n",
            "  - Predicted : [0.02291258 0.88190335 0.88190335 0.69732237 0.88190335 0.88190335\n",
            " 0.88190335 0.88190335 0.88190335]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.327407   0.5985432  0.14800653 0.0982911  0.05938487 0.6305797\n",
            " 0.32059744 0.37367865 0.06004037]\n",
            "  - Predicted : [0.5985432  0.06004037 0.06004037 0.37367865 0.37367865 0.37367865\n",
            " 0.37367865 0.37367865 0.37367865]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.7380188  0.7667568  0.8294355  0.65166336 0.77328855 0.5772264\n",
            " 0.49163705 0.25981253 0.05337753]\n",
            "  - Predicted : [0.8294355 0.8294355 0.8294355 0.8294355 0.8294355 0.8294355 0.8294355\n",
            " 0.8294355 0.8294355]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.29182196 0.68362623 0.92683494 0.25621372 0.66984916 0.47824463\n",
            " 0.6275484  0.00162184 0.12265312]\n",
            "  - Predicted : [0.29182196 0.68362623 0.12265312 0.12265312 0.12265312 0.12265312\n",
            " 0.12265312 0.12265312 0.12265312]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.21702112 0.8934512  0.04052765 0.56963384 0.9286393  0.6520699\n",
            " 0.48440412 0.38599178 0.62419516]\n",
            "  - Predicted : [0.04052765 0.04052765 0.04052765 0.04052765 0.04052765 0.04052765\n",
            " 0.04052765 0.04052765 0.04052765]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.48038515 0.705412   0.6177746  0.5674087  0.95681036 0.8356919\n",
            " 0.6088579  0.5386502  0.72394377]\n",
            "  - Predicted : [0.5674087 0.5674087 0.5674087 0.5674087 0.5674087 0.5674087 0.5674087\n",
            " 0.5674087 0.5674087]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.80391556 0.2952371  0.6669472  0.13515444 0.43045133 0.9384365\n",
            " 0.32629937 0.154235   0.14614585]\n",
            "  - Predicted : [0.6669472 0.6669472 0.6669472 0.6669472 0.6669472 0.6669472 0.6669472\n",
            " 0.6669472 0.6669472]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.39372858 0.22517632 0.4269208  0.7188857  0.88815975 0.11016653\n",
            " 0.76840824 0.10348029 0.37943426]\n",
            "  - Predicted : [0.88815975 0.37943426 0.88815975 0.88815975 0.88815975 0.88815975\n",
            " 0.88815975 0.88815975 0.88815975]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.99654806 0.06867774 0.02288103 0.33364868 0.95112085 0.02003839\n",
            " 0.22271152 0.6031624  0.23375334]\n",
            "  - Predicted : [0.23375334 0.23375334 0.99654806 0.99654806 0.99654806 0.99654806\n",
            " 0.99654806 0.99654806 0.99654806]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.05380761 0.0524447  0.55915934 0.5618939  0.7064738  0.13174114\n",
            " 0.4998517  0.60094917 0.22237585]\n",
            "  - Predicted : [0.05380761 0.7064738  0.7064738  0.7064738  0.7064738  0.7064738\n",
            " 0.7064738  0.7064738  0.7064738 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.54734266 0.70823836 0.9908406  0.59642273 0.8611908  0.83367276\n",
            " 0.9402669  0.7230556  0.21310042]\n",
            "  - Predicted : [0.59642273 0.59642273 0.59642273 0.59642273 0.59642273 0.9908406\n",
            " 0.9908406  0.9908406  0.9908406 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.2980911  0.78468496 0.52082276 0.25130865 0.65667033 0.9065359\n",
            " 0.35768986 0.5962449  0.58150053]\n",
            "  - Predicted : [0.78468496 0.58150053 0.58150053 0.58150053 0.58150053 0.58150053\n",
            " 0.58150053 0.58150053 0.58150053]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.12697467 0.09024499 0.88942677 0.9335369  0.9042418  0.39665478\n",
            " 0.2876201  0.9421723  0.88280237]\n",
            "  - Predicted : [0.9042418  0.88280237 0.88280237 0.88280237 0.88280237 0.88280237\n",
            " 0.88280237 0.88280237 0.88280237]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.81981736 0.334185   0.6387426  0.7504203  0.5761543  0.60200435\n",
            " 0.75668776 0.766828   0.23994866]\n",
            "  - Predicted : [0.7504203 0.6387426 0.6387426 0.7504203 0.7504203 0.7504203 0.7504203\n",
            " 0.7504203 0.7504203]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.3906747  0.78118443 0.26144752 0.915594   0.8388933  0.8954562\n",
            " 0.29729992 0.10511701 0.10059063]\n",
            "  - Predicted : [0.78118443 0.10059063 0.8388933  0.8388933  0.8388933  0.8388933\n",
            " 0.8388933  0.8388933  0.8388933 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.55590755 0.30559045 0.26352167 0.22240539 0.5620976  0.5480952\n",
            " 0.42231268 0.13844003 0.9287948 ]\n",
            "  - Predicted : [0.22240539 0.5480952  0.22240539 0.22240539 0.22240539 0.22240539\n",
            " 0.22240539 0.22240539 0.22240539]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.42793596 0.1236423  0.03707894 0.1525933  0.29712623 0.6300935\n",
            " 0.97093564 0.27206767 0.7898043 ]\n",
            "  - Predicted : [0.27206767 0.27206767 0.27206767 0.27206767 0.27206767 0.27206767\n",
            " 0.27206767 0.27206767 0.27206767]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.9113863  0.39157256 0.2532736  0.4910669  0.8967121  0.01098187\n",
            " 0.48663148 0.75759524 0.6011304 ]\n",
            "  - Predicted : [0.6011304 0.6011304 0.6011304 0.6011304 0.6011304 0.6011304 0.6011304\n",
            " 0.6011304 0.6011304]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.4973394  0.5536132  0.61923164 0.68207514 0.3561856  0.5173746\n",
            " 0.2735702  0.9839901  0.18728806]\n",
            "  - Predicted : [0.68207514 0.68207514 0.68207514 0.68207514 0.68207514 0.68207514\n",
            " 0.68207514 0.68207514 0.68207514]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.15065722 0.26882228 0.92005426 0.65885603 0.45592752 0.9253954\n",
            " 0.9001472  0.4015925  0.56364095]\n",
            "  - Predicted : [0.92005426 0.56364095 0.56364095 0.56364095 0.56364095 0.56364095\n",
            " 0.56364095 0.56364095 0.56364095]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.905374   0.31939867 0.40753722 0.7930146  0.69863886 0.04865039\n",
            " 0.11737644 0.8462639  0.02973874]\n",
            "  - Predicted : [0.02973874 0.02973874 0.02973874 0.02973874 0.02973874 0.02973874\n",
            " 0.02973874 0.02973874 0.02973874]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.9199292  0.27175274 0.5983792  0.56458086 0.39625376 0.03143692\n",
            " 0.19247127 0.6149735  0.44637278]\n",
            "  - Predicted : [0.39625376 0.44637278 0.39625376 0.39625376 0.39625376 0.39625376\n",
            " 0.39625376 0.39625376 0.39625376]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.41383705 0.0977029  0.34712744 0.52643055 0.07769273 0.06669575\n",
            " 0.4915534  0.5612522  0.2576415 ]\n",
            "  - Predicted : [0.5612522 0.5612522 0.5612522 0.5612522 0.5612522 0.5612522 0.5612522\n",
            " 0.5612522 0.5612522]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.32576635 0.7968704  0.86923605 0.3252287  0.35571456 0.83032656\n",
            " 0.9738345  0.3205932  0.78872657]\n",
            "  - Predicted : [0.7968704 0.9738345 0.9738345 0.9738345 0.9738345 0.9738345 0.9738345\n",
            " 0.9738345 0.9738345]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.47969237 0.26372805 0.6817852  0.46255037 0.26816243 0.10722964\n",
            " 0.8669544  0.87866783 0.07496176]\n",
            "  - Predicted : [0.6817852  0.8669544  0.46255037 0.46255037 0.46255037 0.46255037\n",
            " 0.46255037 0.46255037 0.46255037]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.66339535 0.16257744 0.6463201  0.9076172  0.2602147  0.34792924\n",
            " 0.79512995 0.7353738  0.4086553 ]\n",
            "  - Predicted : [0.6463201 0.6463201 0.6463201 0.6463201 0.6463201 0.6463201 0.6463201\n",
            " 0.6463201 0.6463201]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.84854805 0.92058545 0.45264363 0.0394516  0.50944    0.73968244\n",
            " 0.22003575 0.09943032 0.28521463]\n",
            "  - Predicted : [0.0394516 0.0394516 0.0394516 0.0394516 0.0394516 0.0394516 0.0394516\n",
            " 0.0394516 0.0394516]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.01158689 0.71547174 0.14606836 0.723649   0.23454799 0.9920621\n",
            " 0.5317954  0.04133886 0.77267885]\n",
            "  - Predicted : [0.77267885 0.77267885 0.77267885 0.77267885 0.77267885 0.77267885\n",
            " 0.77267885 0.77267885 0.77267885]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.41009024 0.60732126 0.95121324 0.5172698  0.80437636 0.30279282\n",
            " 0.71452105 0.099323   0.89334905]\n",
            "  - Predicted : [0.95121324 0.099323   0.95121324 0.95121324 0.95121324 0.95121324\n",
            " 0.95121324 0.95121324 0.95121324]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.19974741 0.30192953 0.9582119  0.1552136  0.25440976 0.5801793\n",
            " 0.980694   0.6914195  0.11419007]\n",
            "  - Predicted : [0.19974741 0.980694   0.980694   0.980694   0.980694   0.980694\n",
            " 0.980694   0.980694   0.980694  ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.74811715 0.42621547 0.99232894 0.62871706 0.5319559  0.55726516\n",
            " 0.6415618  0.7318293  0.07832184]\n",
            "  - Predicted : [0.99232894 0.99232894 0.99232894 0.99232894 0.99232894 0.99232894\n",
            " 0.99232894 0.99232894 0.99232894]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.13066952 0.3004777  0.47795433 0.3110674  0.21383813 0.9250297\n",
            " 0.03260053 0.9386982  0.9072423 ]\n",
            "  - Predicted : [0.3004777 0.9386982 0.9386982 0.9386982 0.9386982 0.9386982 0.9386982\n",
            " 0.9386982 0.9386982]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.68378174 0.03253458 0.22535557 0.97910064 0.90595037 0.96457195\n",
            " 0.99612314 0.06388747 0.57086253]\n",
            "  - Predicted : [0.22535557 0.03253458 0.03253458 0.22535557 0.22535557 0.22535557\n",
            " 0.22535557 0.22535557 0.22535557]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.8341376  0.31970897 0.43555874 0.28373864 0.03807214 0.07271335\n",
            " 0.02144177 0.52724445 0.6184231 ]\n",
            "  - Predicted : [0.28373864 0.28373864 0.28373864 0.28373864 0.28373864 0.28373864\n",
            " 0.28373864 0.28373864 0.28373864]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.30770168 0.8261485  0.88801336 0.1397483  0.05192446 0.3193806\n",
            " 0.71298754 0.5074239  0.48809   ]\n",
            "  - Predicted : [0.8261485 0.48809   0.48809   0.5074239 0.5074239 0.5074239 0.5074239\n",
            " 0.5074239 0.5074239]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.1524104  0.3514541  0.9588913  0.34056044 0.5914324  0.0583489\n",
            " 0.06385425 0.424254   0.6041123 ]\n",
            "  - Predicted : [0.1524104 0.6041123 0.6041123 0.6041123 0.6041123 0.6041123 0.6041123\n",
            " 0.6041123 0.6041123]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.37234104 0.17901358 0.7359573  0.14004381 0.66801673 0.9567345\n",
            " 0.47053686 0.20043367 0.84198177]\n",
            "  - Predicted : [0.9567345  0.84198177 0.9567345  0.9567345  0.9567345  0.9567345\n",
            " 0.9567345  0.9567345  0.9567345 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.5054762  0.923222   0.72058606 0.4306096  0.61738425 0.16996442\n",
            " 0.3872304  0.5938713  0.5900419 ]\n",
            "  - Predicted : [0.72058606 0.4306096  0.4306096  0.4306096  0.72058606 0.72058606\n",
            " 0.72058606 0.72058606 0.72058606]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.58721536 0.74353606 0.10565338 0.07365709 0.14802071 0.79239434\n",
            " 0.06485375 0.22523548 0.254776  ]\n",
            "  - Predicted : [0.10565338 0.14802071 0.10565338 0.10565338 0.10565338 0.10565338\n",
            " 0.10565338 0.10565338 0.10565338]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.6472516  0.40162954 0.19899322 0.44953847 0.6854513  0.78605187\n",
            " 0.12388319 0.7147156  0.00452266]\n",
            "  - Predicted : [0.19899322 0.44953847 0.19899322 0.19899322 0.19899322 0.19899322\n",
            " 0.19899322 0.19899322 0.19899322]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.7243237  0.6610039  0.46866658 0.13687328 0.764549   0.07175309\n",
            " 0.8955686  0.7734604  0.7409635 ]\n",
            "  - Predicted : [0.46866658 0.6610039  0.6610039  0.46866658 0.46866658 0.46866658\n",
            " 0.46866658 0.46866658 0.46866658]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.75439423 0.06757324 0.9899491  0.8585996  0.50793344 0.7194003\n",
            " 0.73925716 0.8297853  0.25537407]\n",
            "  - Predicted : [0.9899491 0.9899491 0.9899491 0.9899491 0.9899491 0.9899491 0.9899491\n",
            " 0.9899491 0.9899491]\n",
            "\n",
            "\n",
            "\n",
            "loss: 2.9041173\n",
            "\n",
            "\n",
            "Seq: 10 Size: 50\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------\n",
            "====== Actual : [0.37205273 0.7996853  0.7689839  0.5226153  0.39620534 0.96844256\n",
            " 0.4150214  0.7639857  0.41264236 0.30983615]\n",
            "  - Predicted : [0.7689839  0.30983615 0.41264236 0.41264236 0.41264236 0.41264236\n",
            " 0.41264236 0.41264236 0.41264236 0.41264236]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.64099675 0.8076159  0.9813775  0.14890409 0.8761145  0.5241419\n",
            " 0.10774248 0.79437864 0.33154443 0.86824983]\n",
            "  - Predicted : [0.9813775 0.8076159 0.8076159 0.8076159 0.8076159 0.8076159 0.8076159\n",
            " 0.8076159 0.8076159 0.8076159]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.15780187 0.7110917  0.30079627 0.25734875 0.05026016 0.48190868\n",
            " 0.3915024  0.06169036 0.22664225 0.48727185]\n",
            "  - Predicted : [0.15780187 0.30079627 0.30079627 0.7110917  0.7110917  0.7110917\n",
            " 0.7110917  0.7110917  0.7110917  0.7110917 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.8082714  0.9294479  0.51533216 0.40330675 0.9547544  0.9628624\n",
            " 0.19041234 0.5314553  0.8209101  0.822259  ]\n",
            "  - Predicted : [0.40330675 0.822259   0.8082714  0.8082714  0.8082714  0.8082714\n",
            " 0.822259   0.822259   0.822259   0.822259  ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.6849786  0.47146893 0.40365648 0.80641216 0.22572318 0.4284299\n",
            " 0.56686467 0.8317839  0.37385014 0.54865575]\n",
            "  - Predicted : [0.47146893 0.47146893 0.6849786  0.47146893 0.47146893 0.47146893\n",
            " 0.47146893 0.47146893 0.47146893 0.47146893]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.27916384 0.8369127  0.78554124 0.8200983  0.05747629 0.48689812\n",
            " 0.13584282 0.6737604  0.31139094 0.77457625]\n",
            "  - Predicted : [0.8369127  0.77457625 0.77457625 0.77457625 0.77457625 0.77457625\n",
            " 0.77457625 0.77457625 0.77457625 0.77457625]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.06516691 0.51326054 0.12366515 0.5578991  0.6073515  0.4621435\n",
            " 0.2796466  0.03232786 0.66211414 0.8704419 ]\n",
            "  - Predicted : [0.06516691 0.2796466  0.5578991  0.5578991  0.5578991  0.5578991\n",
            " 0.5578991  0.5578991  0.5578991  0.5578991 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.73364776 0.893018   0.9295009  0.44954646 0.6979914  0.39737874\n",
            " 0.91954273 0.56297284 0.75245    0.01451823]\n",
            "  - Predicted : [0.893018   0.01451823 0.73364776 0.893018   0.73364776 0.893018\n",
            " 0.893018   0.893018   0.893018   0.893018  ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.57554924 0.7419911  0.25700617 0.01437397 0.7436328  0.33808583\n",
            " 0.42878962 0.5620524  0.11025117 0.10355267]\n",
            "  - Predicted : [0.25700617 0.10355267 0.7436328  0.7436328  0.7436328  0.7436328\n",
            " 0.7436328  0.7436328  0.7436328  0.7436328 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.96088046 0.3388965  0.25552484 0.04773812 0.17392872 0.4308951\n",
            " 0.34207332 0.42458174 0.7039097  0.6417895 ]\n",
            "  - Predicted : [0.6417895  0.6417895  0.96088046 0.96088046 0.96088046 0.96088046\n",
            " 0.96088046 0.96088046 0.96088046 0.96088046]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.49315307 0.8148215  0.85732454 0.5908127  0.11757103 0.40617922\n",
            " 0.6344635  0.06285101 0.01990653 0.9483344 ]\n",
            "  - Predicted : [0.5908127  0.49315307 0.06285101 0.06285101 0.06285101 0.5908127\n",
            " 0.06285101 0.5908127  0.5908127  0.06285101]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.7300647  0.15310784 0.44512647 0.19355726 0.0102854  0.39169312\n",
            " 0.64838475 0.9541288  0.7698347  0.2301382 ]\n",
            "  - Predicted : [0.15310784 0.15310784 0.0102854  0.15310784 0.44512647 0.44512647\n",
            " 0.44512647 0.15310784 0.15310784 0.15310784]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.3362119  0.52058053 0.19127291 0.8329458  0.1679649  0.28997305\n",
            " 0.57760066 0.12322403 0.62461495 0.9442252 ]\n",
            "  - Predicted : [0.57760066 0.9442252  0.9442252  0.9442252  0.9442252  0.9442252\n",
            " 0.9442252  0.9442252  0.9442252  0.9442252 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.6915359  0.8127846  0.43849438 0.36531726 0.3286027  0.6604652\n",
            " 0.5185357  0.47231942 0.1007461  0.67337316]\n",
            "  - Predicted : [0.8127846 0.1007461 0.6915359 0.8127846 0.6915359 0.8127846 0.8127846\n",
            " 0.8127846 0.8127846 0.8127846]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.7253829  0.19619828 0.75970536 0.87939405 0.17462377 0.4520417\n",
            " 0.8761852  0.48729804 0.81525373 0.2157529 ]\n",
            "  - Predicted : [0.19619828 0.19619828 0.75970536 0.17462377 0.75970536 0.75970536\n",
            " 0.75970536 0.75970536 0.75970536 0.75970536]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.06393124 0.05946685 0.9723564  0.16471781 0.8648912  0.3157286\n",
            " 0.04008855 0.24097729 0.5054925  0.10677183]\n",
            "  - Predicted : [0.06393124 0.8648912  0.9723564  0.9723564  0.9723564  0.9723564\n",
            " 0.9723564  0.9723564  0.9723564  0.9723564 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.92216337 0.89988506 0.14914748 0.73710835 0.46070832 0.98212713\n",
            " 0.05540429 0.4710346  0.28547305 0.7263784 ]\n",
            "  - Predicted : [0.7263784  0.7263784  0.92216337 0.92216337 0.92216337 0.92216337\n",
            " 0.92216337 0.7263784  0.7263784  0.7263784 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.11113425 0.6281087  0.9480593  0.45388043 0.45423067 0.4957023\n",
            " 0.4157082  0.44747594 0.4632387  0.99806595]\n",
            "  - Predicted : [0.11113425 0.9480593  0.9480593  0.99806595 0.99806595 0.99806595\n",
            " 0.99806595 0.99806595 0.99806595 0.99806595]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.11643602 0.2853214  0.21078733 0.544188   0.00280894 0.92109865\n",
            " 0.5311209  0.8960772  0.34496522 0.14992993]\n",
            "  - Predicted : [0.11643602 0.92109865 0.92109865 0.92109865 0.92109865 0.92109865\n",
            " 0.92109865 0.92109865 0.92109865 0.92109865]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.19229256 0.4707324  0.04026891 0.7818041  0.7906366  0.701955\n",
            " 0.89633983 0.5494773  0.47931948 0.52917576]\n",
            "  - Predicted : [0.19229256 0.19229256 0.7818041  0.7818041  0.7818041  0.7818041\n",
            " 0.7818041  0.7818041  0.7818041  0.7818041 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.18195367 0.51229125 0.54175705 0.76458985 0.34791946 0.09222709\n",
            " 0.59746253 0.78795826 0.9695597  0.09025457]\n",
            "  - Predicted : [0.18195367 0.51229125 0.76458985 0.76458985 0.76458985 0.76458985\n",
            " 0.76458985 0.76458985 0.76458985 0.76458985]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.7463511  0.59584004 0.01533718 0.71824163 0.02620125 0.78525615\n",
            " 0.7213222  0.6879201  0.11999617 0.91903293]\n",
            "  - Predicted : [0.59584004 0.91903293 0.7463511  0.7463511  0.7463511  0.59584004\n",
            " 0.59584004 0.59584004 0.59584004 0.59584004]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.8989131  0.900261   0.36036238 0.49217296 0.11489534 0.05109536\n",
            " 0.05877747 0.56876963 0.32140315 0.57955563]\n",
            "  - Predicted : [0.57955563 0.57955563 0.8989131  0.8989131  0.8989131  0.8989131\n",
            " 0.8989131  0.57955563 0.57955563 0.57955563]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.59266436 0.90706235 0.8822833  0.71858346 0.8185034  0.00315964\n",
            " 0.01553514 0.45858732 0.65369374 0.7940842 ]\n",
            "  - Predicted : [0.90706235 0.7940842  0.8185034  0.8185034  0.8185034  0.8185034\n",
            " 0.8185034  0.8185034  0.8185034  0.8185034 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.44726697 0.9401673  0.8149853  0.10275563 0.44017833 0.99487823\n",
            " 0.40994185 0.3862698  0.29408035 0.486489  ]\n",
            "  - Predicted : [0.8149853  0.486489   0.29408035 0.29408035 0.29408035 0.40994185\n",
            " 0.40994185 0.40994185 0.40994185 0.40994185]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.7298571  0.04747191 0.8357176  0.9175796  0.7810926  0.9156349\n",
            " 0.09490447 0.4501076  0.07104246 0.836836  ]\n",
            "  - Predicted : [0.04747191 0.04747191 0.8357176  0.8357176  0.7298571  0.8357176\n",
            " 0.8357176  0.8357176  0.8357176  0.8357176 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.9525468  0.29775122 0.53539467 0.2976755  0.3788725  0.4765576\n",
            " 0.7908025  0.14699748 0.1570543  0.20186207]\n",
            "  - Predicted : [0.20186207 0.20186207 0.9525468  0.9525468  0.9525468  0.9525468\n",
            " 0.9525468  0.20186207 0.20186207 0.20186207]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.05315216 0.6434649  0.1898643  0.437538   0.6855903  0.44894665\n",
            " 0.9060171  0.76916814 0.27302217 0.13040985]\n",
            "  - Predicted : [0.13040985 0.13040985 0.13040985 0.13040985 0.13040985 0.13040985\n",
            " 0.6434649  0.6434649  0.6434649  0.6434649 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.8944378  0.39690766 0.38251182 0.81000406 0.00935479 0.4511123\n",
            " 0.71432006 0.84868646 0.88520885 0.46568018]\n",
            "  - Predicted : [0.00935479 0.39690766 0.46568018 0.46568018 0.8944378  0.8944378\n",
            " 0.8944378  0.46568018 0.46568018 0.46568018]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.84770757 0.03576176 0.30542555 0.0104983  0.16552538 0.72473127\n",
            " 0.00442416 0.5230555  0.41398615 0.12287079]\n",
            "  - Predicted : [0.0104983  0.03576176 0.03576176 0.03576176 0.03576176 0.03576176\n",
            " 0.03576176 0.0104983  0.03576176 0.03576176]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.68563426 0.6931239  0.7263485  0.76530755 0.31499192 0.9941293\n",
            " 0.07295374 0.64769536 0.97077507 0.22431046]\n",
            "  - Predicted : [0.6931239  0.6931239  0.68563426 0.6931239  0.6931239  0.6931239\n",
            " 0.6931239  0.6931239  0.6931239  0.6931239 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.27812493 0.57597744 0.78125757 0.32894698 0.8367752  0.24104379\n",
            " 0.8743667  0.2529531  0.61743516 0.35779122]\n",
            "  - Predicted : [0.57597744 0.78125757 0.35779122 0.35779122 0.35779122 0.35779122\n",
            " 0.35779122 0.35779122 0.35779122 0.35779122]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.3218261  0.35399556 0.49920142 0.8450486  0.75931823 0.44934088\n",
            " 0.28216028 0.854301   0.870185   0.4536763 ]\n",
            "  - Predicted : [0.49920142 0.4536763  0.4536763  0.4536763  0.4536763  0.4536763\n",
            " 0.4536763  0.4536763  0.4536763  0.4536763 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.69584584 0.36926356 0.14909768 0.3214829  0.6820843  0.76940966\n",
            " 0.85165536 0.0177127  0.48640612 0.27392212]\n",
            "  - Predicted : [0.36926356 0.36926356 0.69584584 0.36926356 0.36926356 0.36926356\n",
            " 0.36926356 0.36926356 0.36926356 0.36926356]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.68395954 0.24533133 0.5662802  0.71196264 0.7700649  0.26946828\n",
            " 0.08783215 0.21871337 0.5991314  0.04044919]\n",
            "  - Predicted : [0.5662802  0.24533133 0.68395954 0.24533133 0.24533133 0.24533133\n",
            " 0.24533133 0.24533133 0.24533133 0.24533133]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.15886194 0.99547476 0.38233143 0.49652627 0.01100716 0.5919078\n",
            " 0.3252987  0.5301932  0.52611834 0.9674575 ]\n",
            "  - Predicted : [0.15886194 0.38233143 0.38233143 0.38233143 0.38233143 0.38233143\n",
            " 0.38233143 0.38233143 0.38233143 0.38233143]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.268257   0.5704329  0.3815526  0.4219998  0.05555906 0.688453\n",
            " 0.19528541 0.4684889  0.43426964 0.4681411 ]\n",
            "  - Predicted : [0.5704329 0.3815526 0.4681411 0.4681411 0.4681411 0.4681411 0.4681411\n",
            " 0.4681411 0.4681411 0.4681411]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.375546   0.24238542 0.44871405 0.04621952 0.24232255 0.7848484\n",
            " 0.8428204  0.7153093  0.632564   0.81126577]\n",
            "  - Predicted : [0.44871405 0.632564   0.81126577 0.632564   0.632564   0.632564\n",
            " 0.632564   0.632564   0.632564   0.632564  ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.12783092 0.52525413 0.11631565 0.77786607 0.5205564  0.81002486\n",
            " 0.79906344 0.46621236 0.4968743  0.0282675 ]\n",
            "  - Predicted : [0.12783092 0.11631565 0.77786607 0.81002486 0.81002486 0.81002486\n",
            " 0.81002486 0.81002486 0.81002486 0.81002486]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.5235133  0.6774648  0.23365569 0.98652714 0.9748289  0.2828306\n",
            " 0.71297324 0.03000167 0.6657527  0.62401646]\n",
            "  - Predicted : [0.98652714 0.62401646 0.03000167 0.03000167 0.98652714 0.03000167\n",
            " 0.98652714 0.03000167 0.98652714 0.03000167]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.82215965 0.30436507 0.87801015 0.857975   0.66960293 0.47233486\n",
            " 0.6184012  0.7299588  0.9752514  0.12172819]\n",
            "  - Predicted : [0.857975   0.12172819 0.82215965 0.82215965 0.82215965 0.82215965\n",
            " 0.12172819 0.857975   0.12172819 0.857975  ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.31307277 0.7807163  0.40918002 0.67248    0.13311797 0.7091616\n",
            " 0.6740638  0.5858201  0.765238   0.88011223]\n",
            "  - Predicted : [0.7807163  0.88011223 0.88011223 0.88011223 0.88011223 0.88011223\n",
            " 0.88011223 0.88011223 0.88011223 0.88011223]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.8293026  0.1275741  0.74439335 0.44976443 0.33388183 0.8796496\n",
            " 0.5596132  0.5012347  0.78459936 0.55330855]\n",
            "  - Predicted : [0.44976443 0.55330855 0.8293026  0.8293026  0.8293026  0.8293026\n",
            " 0.55330855 0.44976443 0.44976443 0.44976443]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.8580076  0.10290095 0.77613306 0.16383459 0.22523135 0.17945153\n",
            " 0.23842135 0.7318307  0.65533173 0.2297813 ]\n",
            "  - Predicted : [0.16383459 0.2297813  0.10290095 0.10290095 0.10290095 0.10290095\n",
            " 0.10290095 0.16383459 0.16383459 0.16383459]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.27017495 0.09929411 0.41443554 0.37858516 0.14581579 0.83462507\n",
            " 0.85259503 0.1090468  0.26636595 0.736089  ]\n",
            "  - Predicted : [0.41443554 0.41443554 0.736089   0.736089   0.736089   0.736089\n",
            " 0.736089   0.736089   0.736089   0.736089  ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.8699667  0.07167299 0.90237033 0.06163716 0.63378394 0.02207514\n",
            " 0.92826504 0.35369065 0.64880306 0.1846222 ]\n",
            "  - Predicted : [0.1846222 0.1846222 0.8699667 0.8699667 0.8699667 0.8699667 0.8699667\n",
            " 0.1846222 0.1846222 0.1846222]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.32125542 0.7472985  0.9729959  0.9920533  0.8096795  0.84719306\n",
            " 0.96940386 0.04031669 0.17015044 0.05267778]\n",
            "  - Predicted : [0.7472985  0.05267778 0.05267778 0.05267778 0.05267778 0.9729959\n",
            " 0.05267778 0.05267778 0.9729959  0.05267778]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.50116116 0.95848924 0.5824362  0.5554041  0.8266863  0.9289489\n",
            " 0.69855523 0.8953774  0.17521627 0.50340706]\n",
            "  - Predicted : [0.5554041  0.50116116 0.17521627 0.17521627 0.5554041  0.17521627\n",
            " 0.5554041  0.5554041  0.5554041  0.5554041 ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [3.6460504e-01 3.3252129e-01 2.1425030e-01 8.9399660e-01 4.5036921e-01\n",
            " 5.3025401e-01 2.7631068e-01 9.6285087e-01 6.1120999e-01 6.9417886e-04]\n",
            "  - Predicted : [0.530254   0.00069418 0.00069418 0.61121    0.61121    0.61121\n",
            " 0.61121    0.61121    0.61121    0.61121   ]\n",
            "\n",
            "\n",
            "\n",
            "====== Actual : [0.26789245 0.99934757 0.97477484 0.54461646 0.56411725 0.9015885\n",
            " 0.70856595 0.9322164  0.47913298 0.9759007 ]\n",
            "  - Predicted : [0.99934757 0.97477484 0.9759007  0.9759007  0.9759007  0.9759007\n",
            " 0.9759007  0.9759007  0.9759007  0.9759007 ]\n",
            "\n",
            "\n",
            "\n",
            "loss: 3.1609218\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxQnlRZHFf3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}